{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sentiment_title"
   },
   "source": [
    "# Sentiment Analysis in Natural Language Processing\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vuhung16au/nlp-learning-journey/blob/main/examples/sentiment-analysis.ipynb)\n",
    "\n",
    "## Overview\n",
    "\n",
    "Sentiment Analysis is the process of determining the emotional tone or attitude expressed in text. It's used to identify whether text expresses positive, negative, or neutral sentiment, and can be extended to detect specific emotions.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Understanding sentiment analysis concepts\n",
    "- Rule-based sentiment analysis\n",
    "- Machine learning approaches\n",
    "- Deep learning for sentiment analysis\n",
    "- Handling different types of text\n",
    "- Evaluation metrics\n",
    "- Real-world applications\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Basic understanding of Python, NLP preprocessing, and machine learning concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_libraries"
   },
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install nltk textblob vaderSentiment transformers scikit-learn pandas matplotlib seaborn wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# NLP libraries\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from transformers import pipeline\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Initialize sentiment analyzers\n",
    "vader_analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "understanding_sentiment"
   },
   "source": [
    "## Understanding Sentiment Analysis\n",
    "\n",
    "Sentiment analysis can be performed at different levels:\n",
    "- **Document-level**: Overall sentiment of entire document\n",
    "- **Sentence-level**: Sentiment of individual sentences\n",
    "- **Aspect-level**: Sentiment toward specific aspects/features\n",
    "\n",
    "Common approaches:\n",
    "- **Rule-based**: Using lexicons and linguistic rules\n",
    "- **Machine Learning**: Training models on labeled data\n",
    "- **Deep Learning**: Neural networks and transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sample_texts"
   },
   "outputs": [],
   "source": [
    "# Sample texts for sentiment analysis\n",
    "sample_texts = {\n",
    "    \"Positive\": [\n",
    "        \"I absolutely love this product! It's amazing and works perfectly.\",\n",
    "        \"What a fantastic experience! Highly recommend to everyone.\",\n",
    "        \"Brilliant service and excellent quality. Very satisfied!\"\n",
    "    ],\n",
    "    \"Negative\": [\n",
    "        \"This is the worst product I've ever bought. Complete waste of money.\",\n",
    "        \"Terrible service and poor quality. Very disappointed.\",\n",
    "        \"I hate this! It doesn't work at all and broke after one day.\"\n",
    "    ],\n",
    "    \"Neutral\": [\n",
    "        \"The product arrived on time and matches the description.\",\n",
    "        \"It's an okay product. Nothing special but does the job.\",\n",
    "        \"The item is as expected. Standard quality and features.\"\n",
    "    ],\n",
    "    \"Mixed\": [\n",
    "        \"Great design but poor functionality. Love the look but it doesn't work well.\",\n",
    "        \"Good customer service but the product quality is disappointing.\",\n",
    "        \"Fast delivery which is great, but the item arrived damaged unfortunately.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Sample Texts for Sentiment Analysis:\")\n",
    "for category, texts in sample_texts.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for i, text in enumerate(texts, 1):\n",
    "        print(f\"  {i}. {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "textblob_sentiment"
   },
   "source": [
    "## TextBlob Sentiment Analysis\n",
    "\n",
    "TextBlob provides simple sentiment analysis with polarity (-1 to 1) and subjectivity (0 to 1) scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "textblob_demo"
   },
   "outputs": [],
   "source": [
    "def analyze_sentiment_textblob(text):\n",
    "    \"\"\"Analyze sentiment using TextBlob\"\"\"\n",
    "    blob = TextBlob(text)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    subjectivity = blob.sentiment.subjectivity\n",
    "    \n",
    "    # Classify sentiment\n",
    "    if polarity > 0.1:\n",
    "        sentiment = \"Positive\"\n",
    "    elif polarity < -0.1:\n",
    "        sentiment = \"Negative\"\n",
    "    else:\n",
    "        sentiment = \"Neutral\"\n",
    "    \n",
    "    return {\n",
    "        'sentiment': sentiment,\n",
    "        'polarity': polarity,\n",
    "        'subjectivity': subjectivity\n",
    "    }\n",
    "\n",
    "# Test TextBlob on sample texts\n",
    "print(\"TextBlob Sentiment Analysis Results:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Text':<50} {'Sentiment':<10} {'Polarity':<10} {'Subjectivity':<12}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "for category, texts in sample_texts.items():\n",
    "    for text in texts[:1]:  # One example per category\n",
    "        result = analyze_sentiment_textblob(text)\n",
    "        text_short = text[:47] + \"...\" if len(text) > 50 else text\n",
    "        print(f\"{text_short:<50} {result['sentiment']:<10} {result['polarity']:<10.2f} {result['subjectivity']:<12.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vader_sentiment"
   },
   "source": [
    "## VADER Sentiment Analysis\n",
    "\n",
    "VADER (Valence Aware Dictionary and sEntiment Reasoner) is particularly good for social media text and handles emoticons, slang, and intensifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vader_demo"
   },
   "outputs": [],
   "source": [
    "def analyze_sentiment_vader(text):\n",
    "    \"\"\"Analyze sentiment using VADER\"\"\"\n",
    "    scores = vader_analyzer.polarity_scores(text)\n",
    "    \n",
    "    # Determine sentiment based on compound score\n",
    "    compound = scores['compound']\n",
    "    if compound >= 0.05:\n",
    "        sentiment = \"Positive\"\n",
    "    elif compound <= -0.05:\n",
    "        sentiment = \"Negative\"\n",
    "    else:\n",
    "        sentiment = \"Neutral\"\n",
    "    \n",
    "    return {\n",
    "        'sentiment': sentiment,\n",
    "        'compound': compound,\n",
    "        'positive': scores['pos'],\n",
    "        'negative': scores['neg'],\n",
    "        'neutral': scores['neu']\n",
    "    }\n",
    "\n",
    "# Test VADER on sample texts including social media style\n",
    "social_media_texts = [\n",
    "    \"OMG this is AMAZING!!! 😍😍😍 #love\",\n",
    "    \"This sucks 😞 worst day ever :(\",\n",
    "    \"It's okay I guess... not bad but not great either\",\n",
    "    \"BEST PRODUCT EVER!!!! 5 stars ⭐⭐⭐⭐⭐\",\n",
    "    \"Meh... could be better 🤷‍♀️\"\n",
    "]\n",
    "\n",
    "print(\"VADER Sentiment Analysis Results:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Text':<40} {'Sentiment':<10} {'Compound':<10} {'Pos':<6} {'Neg':<6} {'Neu':<6}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for text in social_media_texts:\n",
    "    result = analyze_sentiment_vader(text)\n",
    "    text_short = text[:37] + \"...\" if len(text) > 40 else text\n",
    "    print(f\"{text_short:<40} {result['sentiment']:<10} {result['compound']:<10.2f} \"\n",
    "          f\"{result['positive']:<6.2f} {result['negative']:<6.2f} {result['neutral']:<6.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "transformer_sentiment"
   },
   "source": [
    "## Transformer-based Sentiment Analysis\n",
    "\n",
    "Using pre-trained transformer models for state-of-the-art sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "transformer_demo"
   },
   "outputs": [],
   "source": [
    "# Initialize transformer-based sentiment analysis pipeline\n",
    "try:\n",
    "    sentiment_pipeline = pipeline(\"sentiment-analysis\", \n",
    "                                 model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "    print(\"Loaded Twitter-specific RoBERTa model\")\n",
    "except:\n",
    "    try:\n",
    "        sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "        print(\"Loaded default sentiment analysis model\")\n",
    "    except:\n",
    "        sentiment_pipeline = None\n",
    "        print(\"Could not load transformer model\")\n",
    "\n",
    "def analyze_sentiment_transformer(text):\n",
    "    \"\"\"Analyze sentiment using transformer model\"\"\"\n",
    "    if sentiment_pipeline is None:\n",
    "        return {\"sentiment\": \"N/A\", \"confidence\": 0.0}\n",
    "    \n",
    "    try:\n",
    "        result = sentiment_pipeline(text)[0]\n",
    "        return {\n",
    "            'sentiment': result['label'],\n",
    "            'confidence': result['score']\n",
    "        }\n",
    "    except:\n",
    "        return {\"sentiment\": \"Error\", \"confidence\": 0.0}\n",
    "\n",
    "# Test transformer model\n",
    "if sentiment_pipeline:\n",
    "    print(\"\\nTransformer Sentiment Analysis Results:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{'Text':<40} {'Sentiment':<15} {'Confidence':<10}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    test_texts = [\n",
    "        \"I love this product so much!\",\n",
    "        \"This is terrible and doesn't work\",\n",
    "        \"It's an average product, nothing special\",\n",
    "        \"Mixed feelings about this purchase\"\n",
    "    ]\n",
    "    \n",
    "    for text in test_texts:\n",
    "        result = analyze_sentiment_transformer(text)\n",
    "        text_short = text[:37] + \"...\" if len(text) > 40 else text\n",
    "        print(f\"{text_short:<40} {result['sentiment']:<15} {result['confidence']:<10.3f}\")\nelse:\n",
    "    print(\"Transformer model not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "comparison"
   },
   "source": [
    "## Comparing Sentiment Analysis Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "method_comparison"
   },
   "outputs": [],
   "source": [
    "def compare_sentiment_methods(texts):\n",
    "    \"\"\"Compare different sentiment analysis methods\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for text in texts:\n",
    "        textblob_result = analyze_sentiment_textblob(text)\n",
    "        vader_result = analyze_sentiment_vader(text)\n",
    "        transformer_result = analyze_sentiment_transformer(text)\n",
    "        \n",
    "        results.append({\n",
    "            'text': text,\n",
    "            'textblob': textblob_result['sentiment'],\n",
    "            'vader': vader_result['sentiment'],\n",
    "            'transformer': transformer_result['sentiment']\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Compare methods on diverse texts\n",
    "comparison_texts = [\n",
    "    \"I absolutely love this! Best purchase ever! 😍\",\n",
    "    \"This is horrible and I hate it completely\",\n",
    "    \"It's okay, nothing special but does the job\",\n",
    "    \"Great quality but too expensive for what it is\",\n",
    "    \"Not bad, could be better though\",\n",
    "    \"AMAZING!!! 5 stars ⭐⭐⭐⭐⭐ #recommended\"\n",
    "]\n",
    "\n",
    "comparison_results = compare_sentiment_methods(comparison_texts)\n",
    "\n",
    "print(\"Sentiment Analysis Method Comparison:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Text':<35} {'TextBlob':<12} {'VADER':<12} {'Transformer':<12}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for result in comparison_results:\n",
    "    text_short = result['text'][:32] + \"...\" if len(result['text']) > 35 else result['text']\n",
    "    print(f\"{text_short:<35} {result['textblob']:<12} {result['vader']:<12} {result['transformer']:<12}\")\n",
    "\n",
    "# Calculate agreement between methods\n",
    "textblob_vader_agreement = sum(1 for r in comparison_results \n",
    "                              if r['textblob'] == r['vader']) / len(comparison_results)\n",
    "textblob_transformer_agreement = sum(1 for r in comparison_results \n",
    "                                    if r['textblob'] == r['transformer']) / len(comparison_results)\n",
    "vader_transformer_agreement = sum(1 for r in comparison_results \n",
    "                                 if r['vader'] == r['transformer']) / len(comparison_results)\n",
    "\n",
    "print(f\"\\nMethod Agreement:\")\n",
    "print(f\"TextBlob vs VADER: {textblob_vader_agreement:.2%}\")\n",
    "print(f\"TextBlob vs Transformer: {textblob_transformer_agreement:.2%}\")\n",
    "print(f\"VADER vs Transformer: {vader_transformer_agreement:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ml_sentiment"
   },
   "source": [
    "## Machine Learning Approach\n",
    "\n",
    "Building a custom sentiment classifier using traditional ML algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ml_classifier"
   },
   "outputs": [],
   "source": [
    "# Create a sample dataset for training\n",
    "def create_sample_dataset():\n",
    "    \"\"\"Create a sample dataset for sentiment classification\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    # Positive examples\n",
    "    positive_texts = [\n",
    "        \"I love this product, it's amazing!\",\n",
    "        \"Excellent quality and fast delivery\",\n",
    "        \"Best purchase I've made this year\",\n",
    "        \"Fantastic service and great results\",\n",
    "        \"Highly recommend to everyone\",\n",
    "        \"Perfect solution to my problem\",\n",
    "        \"Outstanding quality and value\",\n",
    "        \"Exceeded my expectations completely\",\n",
    "        \"Brilliant design and functionality\",\n",
    "        \"Absolutely wonderful experience\"\n",
    "    ]\n",
    "    \n",
    "    # Negative examples\n",
    "    negative_texts = [\n",
    "        \"Terrible product, complete waste of money\",\n",
    "        \"Poor quality and doesn't work properly\",\n",
    "        \"Worst purchase ever, very disappointed\",\n",
    "        \"Broke after one day, terrible quality\",\n",
    "        \"Don't buy this, it's awful\",\n",
    "        \"Completely useless and overpriced\",\n",
    "        \"Horrible experience and poor service\",\n",
    "        \"Failed to meet any expectations\",\n",
    "        \"Waste of time and money\",\n",
    "        \"Extremely poor quality control\"\n",
    "    ]\n",
    "    \n",
    "    # Neutral examples\n",
    "    neutral_texts = [\n",
    "        \"It's an okay product, nothing special\",\n",
    "        \"Average quality, does what it says\",\n",
    "        \"Standard features and decent price\",\n",
    "        \"Neither good nor bad, just average\",\n",
    "        \"Meets basic requirements adequately\",\n",
    "        \"Fair quality for the price point\",\n",
    "        \"Acceptable performance overall\",\n",
    "        \"Regular product with normal features\",\n",
    "        \"Decent but not outstanding\",\n",
    "        \"Works as expected, nothing more\"\n",
    "    ]\n",
    "    \n",
    "    # Combine data\n",
    "    for text in positive_texts:\n",
    "        data.append({'text': text, 'sentiment': 'positive'})\n",
    "    for text in negative_texts:\n",
    "        data.append({'text': text, 'sentiment': 'negative'})\n",
    "    for text in neutral_texts:\n",
    "        data.append({'text': text, 'sentiment': 'neutral'})\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Create and prepare dataset\n",
    "df = create_sample_dataset()\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nSentiment distribution:\")\n",
    "print(df['sentiment'].value_counts())\n",
    "\n",
    "# Text preprocessing\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Simple text preprocessing\"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "df['text_processed'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Split data\n",
    "X = df['text_processed']\n",
    "y = df['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Feature extraction\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Train models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Naive Bayes': MultinomialNB()\n",
    "}\n",
    "\n",
    "trained_models = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_vectorized, y_train)\n",
    "    trained_models[name] = model\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test_vectorized)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n{name} Accuracy: {accuracy:.3f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aspect_sentiment"
   },
   "source": [
    "## Aspect-Based Sentiment Analysis\n",
    "\n",
    "Analyzing sentiment toward specific aspects or features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aspect_analysis"
   },
   "outputs": [],
   "source": [
    "def aspect_based_sentiment_analysis(text, aspects):\n",
    "    \"\"\"Perform aspect-based sentiment analysis\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Split text into sentences\n",
    "    sentences = [s.strip() for s in text.split('.') if s.strip()]\n",
    "    \n",
    "    for aspect in aspects:\n",
    "        aspect_sentiments = []\n",
    "        \n",
    "        # Find sentences mentioning the aspect\n",
    "        for sentence in sentences:\n",
    "            if aspect.lower() in sentence.lower():\n",
    "                # Analyze sentiment of this sentence\n",
    "                sentiment = analyze_sentiment_vader(sentence)\n",
    "                aspect_sentiments.append(sentiment['compound'])\n",
    "        \n",
    "        if aspect_sentiments:\n",
    "            avg_sentiment = np.mean(aspect_sentiments)\n",
    "            if avg_sentiment >= 0.05:\n",
    "                sentiment_label = \"Positive\"\n",
    "            elif avg_sentiment <= -0.05:\n",
    "                sentiment_label = \"Negative\"\n",
    "            else:\n",
    "                sentiment_label = \"Neutral\"\n",
    "            \n",
    "            results[aspect] = {\n",
    "                'sentiment': sentiment_label,\n",
    "                'score': avg_sentiment,\n",
    "                'mentions': len(aspect_sentiments)\n",
    "            }\n",
    "        else:\n",
    "            results[aspect] = {\n",
    "                'sentiment': 'Not Mentioned',\n",
    "                'score': 0.0,\n",
    "                'mentions': 0\n",
    "            }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test aspect-based sentiment analysis\n",
    "review_text = \"\"\"\n",
    "The quality of this phone is excellent and I love the camera features. \n",
    "However, the battery life is disappointing and doesn't last long. \n",
    "The design is beautiful and feels premium in hand. \n",
    "The price is a bit high but the performance makes it worth it. \n",
    "Customer service was helpful when I had questions.\n",
    "\"\"\"\n",
    "\n",
    "aspects = ['quality', 'camera', 'battery', 'design', 'price', 'performance', 'service']\n",
    "\n",
    "aspect_results = aspect_based_sentiment_analysis(review_text, aspects)\n",
    "\n",
    "print(\"Aspect-Based Sentiment Analysis Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Aspect':<12} {'Sentiment':<12} {'Score':<8} {'Mentions':<8}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for aspect, result in aspect_results.items():\n",
    "    print(f\"{aspect:<12} {result['sentiment']:<12} {result['score']:<8.2f} {result['mentions']:<8}\")\n",
    "\n",
    "# Visualize aspect sentiments\n",
    "aspects_mentioned = [aspect for aspect, result in aspect_results.items() \n",
    "                    if result['mentions'] > 0]\n",
    "scores = [aspect_results[aspect]['score'] for aspect in aspects_mentioned]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['green' if score > 0 else 'red' if score < 0 else 'gray' for score in scores]\n",
    "plt.bar(aspects_mentioned, scores, color=colors, alpha=0.7)\n",
    "plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "plt.title('Aspect-Based Sentiment Analysis')\n",
    "plt.xlabel('Aspects')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "real_world_applications"
   },
   "source": [
    "## Real-World Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "applications_demo"
   },
   "outputs": [],
   "source": [
    "# Application 1: Social Media Monitoring\n",
    "def monitor_brand_sentiment(posts):\n",
    "    \"\"\"Monitor brand sentiment from social media posts\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for post in posts:\n",
    "        vader_result = analyze_sentiment_vader(post)\n",
    "        results.append({\n",
    "            'post': post,\n",
    "            'sentiment': vader_result['sentiment'],\n",
    "            'score': vader_result['compound']\n",
    "        })\n",
    "    \n",
    "    # Calculate overall sentiment distribution\n",
    "    sentiments = [r['sentiment'] for r in results]\n",
    "    sentiment_counts = Counter(sentiments)\n",
    "    \n",
    "    return results, sentiment_counts\n",
    "\n",
    "# Application 2: Customer Feedback Analysis\n",
    "def analyze_customer_feedback(feedbacks):\n",
    "    \"\"\"Analyze customer feedback and identify key issues\"\"\"\n",
    "    sentiment_summary = {\n",
    "        'total_reviews': len(feedbacks),\n",
    "        'positive': 0,\n",
    "        'negative': 0,\n",
    "        'neutral': 0,\n",
    "        'avg_score': 0,\n",
    "        'negative_keywords': []\n",
    "    }\n",
    "    \n",
    "    all_scores = []\n",
    "    negative_texts = []\n",
    "    \n",
    "    for feedback in feedbacks:\n",
    "        result = analyze_sentiment_vader(feedback)\n",
    "        score = result['compound']\n",
    "        all_scores.append(score)\n",
    "        \n",
    "        if result['sentiment'] == 'Positive':\n",
    "            sentiment_summary['positive'] += 1\n",
    "        elif result['sentiment'] == 'Negative':\n",
    "            sentiment_summary['negative'] += 1\n",
    "            negative_texts.append(feedback.lower())\n",
    "        else:\n",
    "            sentiment_summary['neutral'] += 1\n",
    "    \n",
    "    sentiment_summary['avg_score'] = np.mean(all_scores)\n",
    "    \n",
    "    # Extract keywords from negative feedback\n",
    "    if negative_texts:\n",
    "        # Simple keyword extraction (in practice, use more sophisticated methods)\n",
    "        negative_words = []\n",
    "        common_negative_keywords = ['bad', 'terrible', 'awful', 'poor', 'hate', \n",
    "                                   'broken', 'defective', 'slow', 'expensive']\n",
    "        \n",
    "        for text in negative_texts:\n",
    "            for keyword in common_negative_keywords:\n",
    "                if keyword in text:\n",
    "                    negative_words.append(keyword)\n",
    "        \n",
    "        sentiment_summary['negative_keywords'] = list(set(negative_words))\n",
    "    \n",
    "    return sentiment_summary\n",
    "\n",
    "# Test applications\n",
    "social_media_posts = [\n",
    "    \"Just tried the new product from @brand - absolutely love it! 😍 #amazing\",\n",
    "    \"Disappointed with my recent purchase from @brand. Poor quality 😞\",\n",
    "    \"@brand has excellent customer service! Quick response and helpful.\",\n",
    "    \"Not impressed with @brand lately. Quality has gone down.\",\n",
    "    \"Great experience with @brand! Will definitely buy again 👍\",\n",
    "    \"@brand products are overpriced for what you get 💸\"\n",
    "]\n",
    "\n",
    "customer_feedbacks = [\n",
    "    \"Great product, excellent quality and fast delivery!\",\n",
    "    \"The item broke after just one week. Very poor quality.\",\n",
    "    \"Average product, nothing special but does the job.\",\n",
    "    \"Terrible customer service and defective product.\",\n",
    "    \"Love this purchase! Exceeded expectations.\",\n",
    "    \"Too expensive for what it offers. Not worth the money.\",\n",
    "    \"Perfect solution to my needs. Highly recommend!\",\n",
    "    \"Product arrived damaged and return process was slow.\"\n",
    "]\n",
    "\n",
    "# Social media monitoring\n",
    "print(\"Social Media Brand Monitoring:\")\n",
    "print(\"=\" * 40)\n",
    "social_results, social_counts = monitor_brand_sentiment(social_media_posts)\n",
    "\n",
    "for sentiment, count in social_counts.items():\n",
    "    percentage = (count / len(social_media_posts)) * 100\n",
    "    print(f\"{sentiment}: {count} posts ({percentage:.1f}%)\")\n",
    "\n",
    "# Customer feedback analysis\n",
    "print(\"\\nCustomer Feedback Analysis:\")\n",
    "print(\"=\" * 40)\n",
    "feedback_summary = analyze_customer_feedback(customer_feedbacks)\n",
    "\n",
    "print(f\"Total Reviews: {feedback_summary['total_reviews']}\")\n",
    "print(f\"Positive: {feedback_summary['positive']} ({feedback_summary['positive']/feedback_summary['total_reviews']*100:.1f}%)\")\n",
    "print(f\"Negative: {feedback_summary['negative']} ({feedback_summary['negative']/feedback_summary['total_reviews']*100:.1f}%)\")\n",
    "print(f\"Neutral: {feedback_summary['neutral']} ({feedback_summary['neutral']/feedback_summary['total_reviews']*100:.1f}%)\")\n",
    "print(f\"Average Sentiment Score: {feedback_summary['avg_score']:.3f}\")\n",
    "print(f\"Negative Keywords Found: {feedback_summary['negative_keywords']}\")\n",
    "\n",
    "# Visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Social media sentiment distribution\n",
    "ax1.pie(social_counts.values(), labels=social_counts.keys(), autopct='%1.1f%%')\n",
    "ax1.set_title('Social Media Sentiment Distribution')\n",
    "\n",
    "# Customer feedback sentiment distribution\n",
    "feedback_labels = ['Positive', 'Negative', 'Neutral']\n",
    "feedback_values = [feedback_summary['positive'], feedback_summary['negative'], feedback_summary['neutral']]\n",
    "ax2.pie(feedback_values, labels=feedback_labels, autopct='%1.1f%%')\n",
    "ax2.set_title('Customer Feedback Sentiment Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exercises"
   },
   "source": [
    "## Exercises\n",
    "\n",
    "1. **Multi-class Emotion Detection**: Extend sentiment analysis to detect specific emotions (joy, anger, fear, sadness, etc.)\n",
    "2. **Domain-Specific Sentiment**: Build sentiment classifiers for specific domains (finance, healthcare, etc.)\n",
    "3. **Sentiment Timeline Analysis**: Track sentiment changes over time\n",
    "4. **Comparative Sentiment**: Compare sentiment between different products/brands\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Multiple approaches available**: Rule-based (VADER), statistical (TextBlob), and neural (transformers)\n",
    "- **Context matters**: Social media text needs different handling than formal reviews\n",
    "- **VADER excels at social media**: Handles emoticons, caps, and slang well\n",
    "- **Transformers provide best accuracy**: But require more computational resources\n",
    "- **Aspect-based analysis**: Provides more granular insights than document-level sentiment\n",
    "- **Consider domain adaptation**: Generic models may not work well for specialized domains\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "1. **Choose the right tool**: VADER for social media, transformers for accuracy, TextBlob for simplicity\n",
    "2. **Preprocess appropriately**: Handle negations, intensifiers, and domain-specific language\n",
    "3. **Validate on your data**: Different domains may need different approaches\n",
    "4. **Consider aspect-level analysis**: More informative than document-level for complex text\n",
    "5. **Handle class imbalance**: Real-world data often has uneven sentiment distribution\n",
    "\n",
    "## Applications\n",
    "\n",
    "- **Brand monitoring**: Track public sentiment about brands/products\n",
    "- **Customer feedback analysis**: Understand customer satisfaction\n",
    "- **Market research**: Analyze public opinion on topics\n",
    "- **Content moderation**: Detect toxic or negative content\n",
    "- **Recommendation systems**: Factor sentiment into recommendations\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Learn about emotion detection and fine-grained sentiment analysis\n",
    "- Explore multimodal sentiment analysis (text + images/audio)\n",
    "- Study temporal sentiment analysis and trend detection\n",
    "- Practice with real-world datasets from your domain of interest\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [VADER Sentiment Analysis](https://github.com/cjhutto/vaderSentiment)\n",
    "- [TextBlob Documentation](https://textblob.readthedocs.io/)\n",
    "- [Hugging Face Sentiment Models](https://huggingface.co/models?pipeline_tag=text-classification)\n",
    "- [Stanford Sentiment Treebank](https://nlp.stanford.edu/sentiment/)\n",
    "- [SemEval Sentiment Analysis Tasks](http://alt.qcri.org/semeval2017/task4/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}