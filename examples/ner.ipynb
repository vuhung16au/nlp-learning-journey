{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ner_title"
   },
   "source": [
    "# Named Entity Recognition (NER) in Natural Language Processing\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vuhung16au/nlp-learning-journey/blob/main/examples/ner.ipynb)\n",
    "\n",
    "## Overview\n",
    "\n",
    "Named Entity Recognition (NER) is the task of identifying and classifying named entities in text into predefined categories such as person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Understanding different types of named entities\n",
    "- Using NLTK for basic NER\n",
    "- Advanced NER with spaCy\n",
    "- Custom entity recognition\n",
    "- Transformer-based NER models\n",
    "- Evaluation metrics for NER\n",
    "- Real-world applications\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Basic understanding of Python, NLP concepts, and tokenization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "environment_setup"
   },
   "outputs": [],
   "source": [
    "# Environment Detection and Setup\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Detect the runtime environment\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "IS_LOCAL = not (IS_COLAB or IS_KAGGLE)\n",
    "\n",
    "print(f\"Environment detected:\")\n",
    "print(f\"  - Local: {IS_LOCAL}\")\n",
    "print(f\"  - Google Colab: {IS_COLAB}\")\n",
    "print(f\"  - Kaggle: {IS_KAGGLE}\")\n",
    "\n",
    "# Platform-specific system setup\n",
    "if IS_COLAB:\n",
    "    print(\"\\nSetting up Google Colab environment...\")\n",
    "    !apt update -qq\n",
    "    !apt install -y -qq libpq-dev\n",
    "elif IS_KAGGLE:\n",
    "    print(\"\\nSetting up Kaggle environment...\")\n",
    "    # Kaggle usually has most packages pre-installed\n",
    "else:\n",
    "    print(\"\\nSetting up local environment...\")\n",
    "\n",
    "# Install required packages for this notebook\n",
    "required_packages = [\n",
    "    \"nltk\",\n",
    "    \"spacy\",\n",
    "    \"pandas\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"transformers\"\n",
    "]\n",
    "\n",
    "print(\"\\nInstalling required packages...\")\n",
    "for package in required_packages:\n",
    "    if IS_COLAB or IS_KAGGLE:\n",
    "        !pip install -q {package}\n",
    "    else:\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package], \n",
    "                      capture_output=True)\n",
    "    print(f\"âœ“ {package}\")\n",
    "\n",
    "# Download spaCy model\n",
    "print(\"\\nDownloading spaCy English model...\")\n",
    "try:\n",
    "    if IS_COLAB or IS_KAGGLE:\n",
    "        !python -m spacy download en_core_web_sm\n",
    "    else:\n",
    "        subprocess.run([sys.executable, \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"], \n",
    "                      capture_output=True)\n",
    "    print(\"âœ“ spaCy model downloaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  spaCy model download failed: {e}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import nltk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "\n",
    "# Download NLTK data with error handling\n",
    "    "nltk_datasets = ['punkt', 'punkt_tab', 'averaged_perceptron_tagger', 'averaged_perceptron_tagger_eng', \n",
    "                 'maxent_ne_chunker', 'maxent_ne_chunker_tab', 'words']\n"\n",
    "print(\"Downloading NLTK datasets...\")\n",
    "for dataset in nltk_datasets:\n",
    "    try:\n",
    "        nltk.download(dataset, quiet=True)\n",
    "        print(f\"âœ“ {dataset}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Failed to download {dataset}: {e}\")\n",
    "\n",
    "# Import NLTK modules\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "from nltk.tree import Tree\n",
    "\n",
    "# Load spaCy model with error handling\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    print(\"âœ“ spaCy model loaded successfully\")\n",
    "except OSError:\n",
    "    print(\"âš ï¸  spaCy model not found. Please run the setup cell above.\")\n",
    "    nlp = None\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "understanding_ner"
   },
   "source": [
    "## Understanding Named Entities\n",
    "\n",
    "Common entity types include:\n",
    "- PERSON: People, including fictional characters\n",
    "- ORGANIZATION: Companies, agencies, institutions\n",
    "- LOCATION: Countries, cities, states\n",
    "- DATE: Dates and time expressions\n",
    "- MONEY: Monetary values\n",
    "- PERCENT: Percentage values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sample_text"
   },
   "outputs": [],
   "source": [
    "# Sample text for NER demonstration\n",
    "sample_text = \"\"\"\n",
    "Apple Inc. announced yesterday that CEO Tim Cook will visit their headquarters in Cupertino, California \n",
    "next month. The company reported quarterly revenue of $81.4 billion, representing a 1% increase from last year.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Sample text:\")\n",
    "print(sample_text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nltk_ner"
   },
   "source": [
    "## NLTK Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nltk_ner_demo"
   },
   "outputs": [],
   "source": [
    "def extract_entities_nltk(text):\n",
    "    \"\"\"Extract named entities using NLTK\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    chunks = ne_chunk(pos_tags)\n",
    "    \n",
    "    entities = []\n",
    "    for chunk in chunks:\n",
    "        if hasattr(chunk, 'label'):\n",
    "            entity_text = ' '.join([token for token, pos in chunk.leaves()])\n",
    "            entity_label = chunk.label()\n",
    "            entities.append((entity_text, entity_label))\n",
    "    \n",
    "    return entities\n",
    "\n",
    "# Test NLTK NER\n",
    "nltk_entities = extract_entities_nltk(sample_text)\n",
    "print(\"NLTK NER Results:\")\n",
    "for entity, label in nltk_entities:\n",
    "    print(f\"  {entity:20} -> {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spacy_ner"
   },
   "source": [
    "## spaCy Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "spacy_ner_demo"
   },
   "outputs": [],
   "source": [
    "def extract_entities_spacy(text):\n",
    "    \"\"\"Extract named entities using spaCy\"\"\"\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append({\n",
    "            'text': ent.text,\n",
    "            'label': ent.label_,\n",
    "            'start': ent.start_char,\n",
    "            'end': ent.end_char,\n",
    "            'description': spacy.explain(ent.label_)\n",
    "        })\n",
    "    \n",
    "    return entities\n",
    "\n",
    "# Test spaCy NER\n",
    "spacy_entities = extract_entities_spacy(sample_text)\n",
    "print(\"spaCy NER Results:\")\n",
    "print(f\"{'Entity':<20} {'Label':<10} {'Description':<30}\")\n",
    "print(\"-\" * 65)\n",
    "for ent in spacy_entities:\n",
    "    print(f\"{ent['text']:<20} {ent['label']:<10} {ent['description']:<30}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization"
   },
   "source": [
    "## Entity Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "entity_analysis"
   },
   "outputs": [],
   "source": [
    "# Analyze entity distribution\n",
    "def analyze_entities(texts):\n",
    "    \"\"\"Analyze entity distribution across multiple texts\"\"\"\n",
    "    all_entities = []\n",
    "    \n",
    "    for text in texts:\n",
    "        entities = extract_entities_spacy(text)\n",
    "        all_entities.extend(entities)\n",
    "    \n",
    "    # Count entity types\n",
    "    entity_counts = Counter([ent['label'] for ent in all_entities])\n",
    "    \n",
    "    return entity_counts, all_entities\n",
    "\n",
    "# Example texts\n",
    "example_texts = [\n",
    "    sample_text,\n",
    "    \"Microsoft reported strong earnings. CEO Satya Nadella praised the team's performance in Seattle.\",\n",
    "    \"The meeting is scheduled for January 15, 2024, at 2:30 PM in New York. Budget allocation is $2.5 million.\"\n",
    "]\n",
    "\n",
    "entity_counts, all_entities = analyze_entities(example_texts)\n",
    "\n",
    "print(\"Entity Type Distribution:\")\n",
    "for entity_type, count in entity_counts.most_common():\n",
    "    print(f\"  {entity_type}: {count}\")\n",
    "\n",
    "# Create visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "entity_types = list(entity_counts.keys())\n",
    "counts = list(entity_counts.values())\n",
    "\n",
    "plt.bar(entity_types, counts)\n",
    "plt.title('Named Entity Distribution')\n",
    "plt.xlabel('Entity Type')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "custom_ner"
   },
   "source": [
    "## Custom Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "custom_ner_demo"
   },
   "outputs": [],
   "source": [
    "def custom_entity_recognizer(text):\n",
    "    \"\"\"Custom entity recognizer for domain-specific entities\"\"\"\n",
    "    entities = []\n",
    "    \n",
    "    # Custom patterns\n",
    "    patterns = {\n",
    "        'EMAIL': r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',\n",
    "        'PHONE': r'\\b(?:\\+?1[-.]?)?\\(?([0-9]{3})\\)?[-.]?([0-9]{3})[-.]?([0-9]{4})\\b',\n",
    "        'URL': r'https?://[^\\s]+',\n",
    "        'PRODUCT_CODE': r'\\b[A-Z]{2,3}-\\d{3,6}\\b',\n",
    "        'VERSION': r'\\bv?\\d+\\.\\d+(?:\\.\\d+)?\\b'\n",
    "    }\n",
    "    \n",
    "    for entity_type, pattern in patterns.items():\n",
    "        matches = re.finditer(pattern, text, re.IGNORECASE)\n",
    "        for match in matches:\n",
    "            entities.append({\n",
    "                'text': match.group(),\n",
    "                'label': entity_type,\n",
    "                'start': match.start(),\n",
    "                'end': match.end()\n",
    "            })\n",
    "    \n",
    "    return entities\n",
    "\n",
    "# Test custom NER\n",
    "custom_text = \"\"\"\n",
    "Contact support at help@company.com or call (555) 123-4567.\n",
    "Visit https://example.com for product ABC-12345 version 2.1.0.\n",
    "\"\"\"\n",
    "\n",
    "custom_entities = custom_entity_recognizer(custom_text)\n",
    "print(\"Custom NER Results:\")\n",
    "for ent in custom_entities:\n",
    "    print(f\"  {ent['text']:20} -> {ent['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "applications"
   },
   "source": [
    "## Real-World Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "applications_demo"
   },
   "outputs": [],
   "source": [
    "# Application 1: Information Extraction\n",
    "def extract_key_info(text):\n",
    "    \"\"\"Extract key information from text\"\"\"\n",
    "    entities = extract_entities_spacy(text)\n",
    "    \n",
    "    info = {\n",
    "        'people': [ent['text'] for ent in entities if ent['label'] == 'PERSON'],\n",
    "        'organizations': [ent['text'] for ent in entities if ent['label'] == 'ORG'],\n",
    "        'locations': [ent['text'] for ent in entities if ent['label'] in ['GPE', 'LOC']],\n",
    "        'dates': [ent['text'] for ent in entities if ent['label'] == 'DATE'],\n",
    "        'money': [ent['text'] for ent in entities if ent['label'] == 'MONEY']\n",
    "    }\n",
    "    \n",
    "    return info\n",
    "\n",
    "# Application 2: Privacy Protection\n",
    "def mask_sensitive_entities(text):\n",
    "    \"\"\"Mask sensitive information in text\"\"\"\n",
    "    entities = extract_entities_spacy(text)\n",
    "    custom_entities = custom_entity_recognizer(text)\n",
    "    \n",
    "    # Combine entities\n",
    "    all_entities = entities + custom_entities\n",
    "    \n",
    "    # Sort by start position (reverse order for replacement)\n",
    "    all_entities.sort(key=lambda x: x['start'], reverse=True)\n",
    "    \n",
    "    masked_text = text\n",
    "    sensitive_types = ['PERSON', 'EMAIL', 'PHONE']\n",
    "    \n",
    "    for ent in all_entities:\n",
    "        if ent['label'] in sensitive_types:\n",
    "            mask = f\"[{ent['label']}]\"\n",
    "            masked_text = masked_text[:ent['start']] + mask + masked_text[ent['end']:]\n",
    "    \n",
    "    return masked_text\n",
    "\n",
    "# Test applications\n",
    "news_text = \"\"\"\n",
    "Apple CEO Tim Cook announced record quarterly earnings of $89.5 billion \n",
    "during a conference call yesterday from Cupertino, California.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Information Extraction:\")\n",
    "info = extract_key_info(news_text)\n",
    "for category, items in info.items():\n",
    "    if items:\n",
    "        print(f\"  {category.title()}: {items}\")\n",
    "\n",
    "sensitive_text = \"\"\"\n",
    "Please contact John Smith at john.smith@email.com or call (555) 123-4567 \n",
    "regarding the urgent matter.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nPrivacy Protection:\")\n",
    "print(f\"Original: {sensitive_text.strip()}\")\n",
    "print(f\"Masked: {mask_sensitive_entities(sensitive_text).strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exercises"
   },
   "source": [
    "## Exercises\n",
    "\n",
    "1. **Domain-Specific NER**: Create a custom NER system for medical, legal, or financial text\n",
    "2. **Entity Linking**: Connect identified entities to a knowledge base\n",
    "3. **Multilingual NER**: Handle entities in multiple languages\n",
    "4. **Entity Resolution**: Identify when different mentions refer to the same entity\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- NER is essential for information extraction and text understanding\n",
    "- spaCy provides production-ready NER with high accuracy\n",
    "- Custom patterns can handle domain-specific entities\n",
    "- Combining multiple approaches often yields better results\n",
    "- Consider privacy implications when processing personal data\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Learn about relationship extraction\n",
    "- Explore entity linking and knowledge graphs\n",
    "- Study coreference resolution\n",
    "- Practice with domain-specific datasets\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [spaCy NER Documentation](https://spacy.io/usage/linguistic-features#named-entities)\n",
    "- [NLTK Named Entity Recognition](https://www.nltk.org/book/ch07.html)\n",
    "- [CoNLL-2003 NER Dataset](https://www.clips.uantwerpen.be/conll2003/ner/)\n",
    "- [OntoNotes 5.0](https://catalog.ldc.upenn.edu/LDC2013T19)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}