{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "generation_title"
   },
   "source": [
    "# Text Generation in Natural Language Processing\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vuhung16au/nlp-learning-journey/blob/main/examples/text-generation.ipynb)\n",
    "\n",
    "## Overview\n",
    "\n",
    "Text generation is the task of automatically producing coherent and contextually relevant text. It ranges from simple template-based approaches to sophisticated neural language models that can generate human-like text.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- N-gram based text generation\n",
    "- Markov chain approaches\n",
    "- Neural language models\n",
    "- Transformer-based generation\n",
    "- Conditional text generation\n",
    "- Evaluation techniques\n",
    "- Real-world applications\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Basic understanding of Python, probability, NLP concepts, and neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup"
   },
   "outputs": [],
   "source": [
    "# Environment Detection and Setup\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Detect the runtime environment\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "IS_LOCAL = not (IS_COLAB or IS_KAGGLE)\n",
    "\n",
    "print(f\"Environment detected:\")\n",
    "print(f\"  - Local: {IS_LOCAL}\")\n",
    "print(f\"  - Google Colab: {IS_COLAB}\")\n",
    "print(f\"  - Kaggle: {IS_KAGGLE}\")\n",
    "\n",
    "# Platform-specific system setup\n",
    "if IS_COLAB:\n",
    "    print(\"\\nSetting up Google Colab environment...\")\n",
    "    !apt update -qq\n",
    "    !apt install -y -qq libpq-dev\n",
    "elif IS_KAGGLE:\n",
    "    print(\"\\nSetting up Kaggle environment...\")\n",
    "    # Kaggle usually has most packages pre-installed\n",
    "else:\n",
    "    print(\"\\nSetting up local environment...\")\n",
    "\n",
    "# Install required packages for this notebook\n",
    "required_packages = [\n",
    "    \"transformers\",\n",
    "    \"torch\",\n",
    "    \"nltk\",\n",
    "    \"pandas\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"wordcloud\"\n",
    "]\n",
    "\n",
    "print(\"\\nInstalling required packages...\")\n",
    "for package in required_packages:\n",
    "    if IS_COLAB or IS_KAGGLE:\n",
    "        !pip install -q {package}\n",
    "    else:\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package], \n",
    "                      capture_output=True)\n",
    "    print(f\"‚úì {package}\")\n",
    "\n",
    "print(\"\\nüéâ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import re\n",
    "\n",
    "# NLP libraries\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data with error handling\n",
    "nltk_datasets = ['punkt', 'punkt_tab', 'gutenberg']\n",
    "print(\"Downloading NLTK datasets...\")\n",
    "for dataset in nltk_datasets:\n",
    "    try:\n",
    "        nltk.download(dataset, quiet=True)\n",
    "        print(f\"‚úì {dataset}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Failed to download {dataset}: {e}\")\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "try:\n",
    "    from nltk.corpus import gutenberg\n",
    "    print(\"‚úì NLTK corpus loaded\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è  NLTK corpus not available\")\n",
    "    gutenberg = None\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Note: Transformers models will be loaded when needed due to potential network requirements\n",
    "print(\"\\n‚ö†Ô∏è  Note: Transformer models (GPT-2, etc.) require internet access and will be loaded when needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sample_corpus"
   },
   "source": [
    "## Sample Text Corpus\n",
    "\n",
    "Let's create a sample corpus for training our text generation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_corpus"
   },
   "outputs": [],
   "source": [
    "def create_sample_corpus():\n",
    "    \"\"\"Create a sample text corpus for training\"\"\"\n",
    "    \n",
    "    # Technology-related sentences\n",
    "    tech_sentences = [\n",
    "        \"Artificial intelligence is transforming the way we work and live.\",\n",
    "        \"Machine learning algorithms can learn patterns from data automatically.\",\n",
    "        \"Deep learning models use neural networks with multiple layers.\",\n",
    "        \"Natural language processing enables computers to understand human language.\",\n",
    "        \"Computer vision systems can recognize objects in images and videos.\",\n",
    "        \"Cloud computing provides scalable infrastructure for modern applications.\",\n",
    "        \"Data science combines statistics, programming, and domain expertise.\",\n",
    "        \"Software development requires careful planning and systematic implementation.\",\n",
    "        \"Cybersecurity protects digital systems from malicious attacks.\",\n",
    "        \"The internet connects billions of devices around the world.\"\n",
    "    ]\n",
    "    \n",
    "    # Science-related sentences\n",
    "    science_sentences = [\n",
    "        \"Scientists conduct experiments to test their hypotheses.\",\n",
    "        \"Research findings contribute to our understanding of the natural world.\",\n",
    "        \"The scientific method involves observation, hypothesis, and experimentation.\",\n",
    "        \"Peer review ensures the quality and validity of scientific publications.\",\n",
    "        \"Innovation often emerges from interdisciplinary collaboration.\",\n",
    "        \"Laboratory equipment enables precise measurement and analysis.\",\n",
    "        \"Mathematical models help scientists predict natural phenomena.\",\n",
    "        \"Evidence-based conclusions form the foundation of scientific knowledge.\",\n",
    "        \"Technology transfer brings scientific discoveries to practical applications.\",\n",
    "        \"Scientific literacy is essential for informed decision making.\"\n",
    "    ]\n",
    "    \n",
    "    # Australia-related sentences\n",
    "    australia_sentences = [\n",
    "        \"Australia is known for its unique wildlife including kangaroos and koalas.\",\n",
    "        \"The Great Barrier Reef is one of Australia's most famous natural wonders.\",\n",
    "        \"Sydney Opera House is an iconic architectural landmark in Australia.\",\n",
    "        \"Australia has diverse landscapes from deserts to tropical rainforests.\",\n",
    "        \"Melbourne is renowned for its vibrant arts and coffee culture.\",\n",
    "        \"The Australian Outback covers vast areas of the continent's interior.\",\n",
    "        \"Australia's indigenous Aboriginal culture spans over 65,000 years.\",\n",
    "        \"The country is famous for its beautiful beaches and coastal cities.\",\n",
    "        \"Australia is home to many venomous snakes and dangerous wildlife.\",\n",
    "        \"The Australian economy relies heavily on mining and agriculture exports.\"\n",
    "    ]\n",
    "    \n",
    "    # Combine all sentences\n",
    "    corpus_sentences = tech_sentences + science_sentences + australia_sentences\n",
    "    \n",
    "    # Create a larger corpus by adding some variety\n",
    "    extended_corpus = []\n",
    "    for sentence in corpus_sentences:\n",
    "        extended_corpus.append(sentence)\n",
    "        # Add some variations\n",
    "        if \"can\" in sentence:\n",
    "            extended_corpus.append(sentence.replace(\"can\", \"may\"))\n",
    "        if \"is\" in sentence:\n",
    "            extended_corpus.append(sentence.replace(\"is\", \"was\"))\n",
    "    \n",
    "    return extended_corpus\n",
    "\n",
    "# Create corpus\n",
    "corpus = create_sample_corpus()\n",
    "print(f\"Corpus size: {len(corpus)} sentences\")\n",
    "print(\"\\nSample sentences:\")\n",
    "for i in range(5):\n",
    "    print(f\"{i+1}. {corpus[i]}\")\n",
    "\n",
    "# Create combined text\n",
    "corpus_text = ' '.join(corpus)\n",
    "print(f\"\\nTotal characters: {len(corpus_text)}\")\n",
    "print(f\"Total words: {len(corpus_text.split())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngram_generation"
   },
   "source": [
    "## N-gram Based Text Generation\n",
    "\n",
    "Simple probabilistic approach using n-grams to generate text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ngram_model"
   },
   "outputs": [],
   "source": [
    "class NGramGenerator:\n",
    "    def __init__(self, n=2):\n",
    "        self.n = n\n",
    "        self.ngram_counts = defaultdict(Counter)\n",
    "        self.vocab = set()\n",
    "    \n",
    "    def train(self, text):\n",
    "        \"\"\"Train the n-gram model on text\"\"\"\n",
    "        # Tokenize text\n",
    "        words = word_tokenize(text.lower())\n",
    "        words = [word for word in words if word.isalnum()]\n",
    "        \n",
    "        # Add special tokens\n",
    "        words = ['<START>'] * (self.n - 1) + words + ['<END>']\n",
    "        self.vocab.update(words)\n",
    "        \n",
    "        # Count n-grams\n",
    "        for i in range(len(words) - self.n + 1):\n",
    "            context = tuple(words[i:i + self.n - 1])\n",
    "            next_word = words[i + self.n - 1]\n",
    "            self.ngram_counts[context][next_word] += 1\n",
    "    \n",
    "    def generate_text(self, max_length=50, temperature=1.0):\n",
    "        \"\"\"Generate text using the trained model\"\"\"\n",
    "        # Start with context\n",
    "        context = ['<START>'] * (self.n - 1)\n",
    "        generated = []\n",
    "        \n",
    "        for _ in range(max_length):\n",
    "            context_tuple = tuple(context[-(self.n-1):])\n",
    "            \n",
    "            if context_tuple not in self.ngram_counts:\n",
    "                break\n",
    "            \n",
    "            # Get possible next words\n",
    "            candidates = self.ngram_counts[context_tuple]\n",
    "            \n",
    "            if not candidates:\n",
    "                break\n",
    "            \n",
    "            # Apply temperature to probabilities\n",
    "            words = list(candidates.keys())\n",
    "            counts = np.array(list(candidates.values()), dtype=float)\n",
    "            \n",
    "            if temperature != 1.0:\n",
    "                counts = counts ** (1.0 / temperature)\n",
    "            \n",
    "            probabilities = counts / counts.sum()\n",
    "            \n",
    "            # Sample next word\n",
    "            next_word = np.random.choice(words, p=probabilities)\n",
    "            \n",
    "            if next_word == '<END>':\n",
    "                break\n",
    "            \n",
    "            generated.append(next_word)\n",
    "            context.append(next_word)\n",
    "        \n",
    "        return ' '.join(generated)\n",
    "    \n",
    "    def get_statistics(self):\n",
    "        \"\"\"Get model statistics\"\"\"\n",
    "        total_ngrams = sum(len(counts) for counts in self.ngram_counts.values())\n",
    "        total_contexts = len(self.ngram_counts)\n",
    "        \n",
    "        return {\n",
    "            'vocabulary_size': len(self.vocab),\n",
    "            'total_ngrams': total_ngrams,\n",
    "            'unique_contexts': total_contexts,\n",
    "            'avg_choices_per_context': total_ngrams / total_contexts if total_contexts > 0 else 0\n",
    "        }\n",
    "\n",
    "# Train n-gram models with different n values\n",
    "print(\"N-gram Text Generation:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "models = {}\n",
    "for n in [2, 3, 4]:\n",
    "    model = NGramGenerator(n=n)\n",
    "    model.train(corpus_text)\n",
    "    models[n] = model\n",
    "    \n",
    "    stats = model.get_statistics()\n",
    "    print(f\"\\n{n}-gram model statistics:\")\n",
    "    for key, value in stats.items():\n",
    "        print(f\"  {key}: {value:.2f}\")\n",
    "\n",
    "# Generate text with different models\n",
    "print(\"\\nGenerated Text Examples:\")\n",
    "for n in [2, 3, 4]:\n",
    "    print(f\"\\n{n}-gram model:\")\n",
    "    for temp in [0.5, 1.0, 1.5]:\n",
    "        generated = models[n].generate_text(max_length=20, temperature=temp)\n",
    "        print(f\"  Temp {temp}: {generated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "markov_generation"
   },
   "source": [
    "## Markov Chain Text Generation\n",
    "\n",
    "Character-level Markov chain for text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "markov_model"
   },
   "outputs": [],
   "source": [
    "class MarkovTextGenerator:\n",
    "    def __init__(self, order=2):\n",
    "        self.order = order\n",
    "        self.transitions = defaultdict(Counter)\n",
    "    \n",
    "    def train(self, text):\n",
    "        \"\"\"Train Markov chain on character sequences\"\"\"\n",
    "        # Clean text\n",
    "        text = re.sub(r'[^a-zA-Z\\s.,!?]', '', text)\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Build transition table\n",
    "        for i in range(len(text) - self.order):\n",
    "            state = text[i:i + self.order]\n",
    "            next_char = text[i + self.order]\n",
    "            self.transitions[state][next_char] += 1\n",
    "    \n",
    "    def generate_text(self, length=200, seed=None):\n",
    "        \"\"\"Generate text using Markov chain\"\"\"\n",
    "        if not self.transitions:\n",
    "            return \"Model not trained\"\n",
    "        \n",
    "        # Choose starting state\n",
    "        if seed and len(seed) >= self.order:\n",
    "            current_state = seed[-self.order:].lower()\n",
    "        else:\n",
    "            # Find states that start with capital letters (sentence beginnings)\n",
    "            sentence_starts = [state for state in self.transitions.keys() \n",
    "                             if state[0].isupper() or state.startswith(' ')]\n",
    "            if sentence_starts:\n",
    "                current_state = random.choice(sentence_starts)\n",
    "            else:\n",
    "                current_state = random.choice(list(self.transitions.keys()))\n",
    "        \n",
    "        result = current_state\n",
    "        \n",
    "        for _ in range(length - self.order):\n",
    "            if current_state not in self.transitions:\n",
    "                break\n",
    "            \n",
    "            # Get possible next characters\n",
    "            candidates = self.transitions[current_state]\n",
    "            \n",
    "            if not candidates:\n",
    "                break\n",
    "            \n",
    "            # Choose next character based on probabilities\n",
    "            chars = list(candidates.keys())\n",
    "            weights = list(candidates.values())\n",
    "            next_char = random.choices(chars, weights=weights)[0]\n",
    "            \n",
    "            result += next_char\n",
    "            current_state = current_state[1:] + next_char\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_statistics(self):\n",
    "        \"\"\"Get model statistics\"\"\"\n",
    "        total_transitions = sum(sum(counter.values()) for counter in self.transitions.values())\n",
    "        avg_choices = np.mean([len(counter) for counter in self.transitions.values()])\n",
    "        \n",
    "        return {\n",
    "            'unique_states': len(self.transitions),\n",
    "            'total_transitions': total_transitions,\n",
    "            'avg_choices_per_state': avg_choices\n",
    "        }\n",
    "\n",
    "# Train Markov models with different orders\n",
    "print(\"Markov Chain Text Generation:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "markov_models = {}\n",
    "for order in [2, 3, 4]:\n",
    "    model = MarkovTextGenerator(order=order)\n",
    "    model.train(corpus_text)\n",
    "    markov_models[order] = model\n",
    "    \n",
    "    stats = model.get_statistics()\n",
    "    print(f\"\\nOrder {order} Markov model:\")\n",
    "    for key, value in stats.items():\n",
    "        print(f\"  {key}: {value:.2f}\")\n",
    "\n",
    "# Generate text examples\n",
    "print(\"\\nMarkov Chain Generated Text:\")\n",
    "for order in [2, 3, 4]:\n",
    "    generated = markov_models[order].generate_text(length=150)\n",
    "    print(f\"\\nOrder {order}: {generated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "transformer_generation"
   },
   "source": [
    "## Transformer-Based Text Generation\n",
    "\n",
    "Using pre-trained language models for high-quality text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "transformer_models"
   },
   "outputs": [],
   "source": [
    "# Initialize text generation pipeline\n",
    "try:\n",
    "    # Try to load GPT-2\n",
    "    generator = pipeline('text-generation', model='gpt2', tokenizer='gpt2')\n",
    "    print(\"Loaded GPT-2 model for text generation\")\nexcept:\n",
    "    try:\n",
    "        # Fallback to DistilGPT-2\n",
    "        generator = pipeline('text-generation', model='distilgpt2')\n",
    "        print(\"Loaded DistilGPT-2 model for text generation\")\n",
    "    except:\n",
    "        generator = None\n",
    "        print(\"Could not load transformer generation model\")\n",
    "\n",
    "def transformer_text_generation(prompt, max_length=100, num_return_sequences=3, \n",
    "                               temperature=0.7, top_p=0.9):\n",
    "    \"\"\"Generate text using transformer model\"\"\"\n",
    "    if generator is None:\n",
    "        return [\"Transformer model not available\"]\n",
    "    \n",
    "    try:\n",
    "        results = generator(\n",
    "            prompt,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=num_return_sequences,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            do_sample=True,\n",
    "            pad_token_id=generator.tokenizer.eos_token_id\n",
    "        )\n",
    "        \n",
    "        return [result['generated_text'] for result in results]\n",
    "    except Exception as e:\n",
    "        return [f\"Error in generation: {str(e)}\"]\n",
    "\n",
    "if generator:\n",
    "    print(\"\\nTransformer Text Generation Examples:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Test different prompts\n",
    "    prompts = [\n",
    "        \"Artificial intelligence will\",\n",
    "        \"The future of technology\",\n",
    "        \"Scientists have discovered\"\n",
    "    ]\n",
    "    \n",
    "    for prompt in prompts:\n",
    "        print(f\"\\nPrompt: '{prompt}'\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        generations = transformer_text_generation(\n",
    "            prompt, max_length=80, num_return_sequences=2\n",
    "        )\n",
    "        \n",
    "        for i, gen_text in enumerate(generations, 1):\n",
    "            # Clean up the generated text\n",
    "            clean_text = gen_text.replace(prompt, '').strip()\n",
    "            if clean_text:\n",
    "                print(f\"  {i}. {prompt}{clean_text}\")\n",
    "            else:\n",
    "                print(f\"  {i}. {gen_text}\")\nelse:\n",
    "    print(\"Transformer generation not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conditional_generation"
   },
   "source": [
    "## Conditional Text Generation\n",
    "\n",
    "Generating text based on specific conditions or constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "conditional_approaches"
   },
   "outputs": [],
   "source": [
    "class ConditionalGenerator:\n",
    "    def __init__(self):\n",
    "        self.topic_keywords = {\n",
    "            'technology': ['artificial', 'intelligence', 'computer', 'software', 'data', 'algorithm'],\n",
    "            'science': ['research', 'experiment', 'discovery', 'scientific', 'laboratory', 'hypothesis'],\n",
    "            'health': ['medical', 'treatment', 'patient', 'doctor', 'medicine', 'therapy'],\n",
    "            'education': ['learning', 'student', 'teacher', 'school', 'knowledge', 'study']\n",
    "        }\n",
    "        \n",
    "        self.sentence_templates = {\n",
    "            'technology': [\n",
    "                \"The latest {tech_term} technology enables {benefit}.\",\n",
    "                \"Researchers are developing {tech_term} systems for {application}.\",\n",
    "                \"Advanced {tech_term} algorithms can {capability}.\"\n",
    "            ],\n",
    "            'science': [\n",
    "                \"Scientists have conducted {study_type} to investigate {phenomenon}.\",\n",
    "                \"The research findings suggest that {discovery}.\",\n",
    "                \"Laboratory experiments demonstrate {result}.\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        self.template_fillers = {\n",
    "            'tech_term': ['AI', 'machine learning', 'blockchain', 'quantum computing'],\n",
    "            'benefit': ['improved efficiency', 'better accuracy', 'cost reduction'],\n",
    "            'application': ['healthcare', 'finance', 'transportation', 'education'],\n",
    "            'capability': ['process large datasets', 'recognize patterns', 'make predictions'],\n",
    "            'study_type': ['comprehensive studies', 'controlled experiments', 'longitudinal research'],\n",
    "            'phenomenon': ['climate change effects', 'cellular behavior', 'quantum mechanics'],\n",
    "            'discovery': ['new mechanisms exist', 'correlations are significant', 'theories need revision'],\n",
    "            'result': ['promising outcomes', 'unexpected findings', 'measurable improvements']\n",
    "        }\n",
    "    \n",
    "    def generate_by_topic(self, topic, num_sentences=3):\n",
    "        \"\"\"Generate text focused on a specific topic\"\"\"\n",
    "        if topic not in self.topic_keywords:\n",
    "            return f\"Topic '{topic}' not supported\"\n",
    "        \n",
    "        sentences = []\n",
    "        \n",
    "        if topic in self.sentence_templates:\n",
    "            templates = self.sentence_templates[topic]\n",
    "            \n",
    "            for _ in range(num_sentences):\n",
    "                template = random.choice(templates)\n",
    "                \n",
    "                # Fill template placeholders\n",
    "                filled_template = template\n",
    "                for placeholder, options in self.template_fillers.items():\n",
    "                    if '{' + placeholder + '}' in filled_template:\n",
    "                        filled_template = filled_template.replace(\n",
    "                            '{' + placeholder + '}', random.choice(options)\n",
    "                        )\n",
    "                \n",
    "                sentences.append(filled_template)\n",
    "        else:\n",
    "            # Fallback: generate sentences with topic keywords\n",
    "            keywords = self.topic_keywords[topic]\n",
    "            base_sentences = [\n",
    "                f\"Recent advances in {random.choice(keywords)} are promising.\",\n",
    "                f\"The field of {random.choice(keywords)} continues to evolve.\",\n",
    "                f\"New developments in {random.choice(keywords)} show potential.\"\n",
    "            ]\n",
    "            sentences = random.sample(base_sentences, min(num_sentences, len(base_sentences)))\n",
    "        \n",
    "        return ' '.join(sentences)\n",
    "    \n",
    "    def generate_with_length_constraint(self, topic, target_length=100):\n",
    "        \"\"\"Generate text with specific length constraint\"\"\"\n",
    "        generated_text = \"\"\n",
    "        \n",
    "        while len(generated_text.split()) < target_length:\n",
    "            sentence = self.generate_by_topic(topic, num_sentences=1)\n",
    "            generated_text += sentence + \" \"\n",
    "            \n",
    "            # Prevent infinite loop\n",
    "            if len(generated_text.split()) > target_length * 1.5:\n",
    "                break\n",
    "        \n",
    "        # Trim to approximate target length\n",
    "        words = generated_text.split()[:target_length]\n",
    "        return ' '.join(words)\n",
    "    \n",
    "    def generate_with_keywords(self, required_keywords, num_sentences=3):\n",
    "        \"\"\"Generate text that includes specific keywords\"\"\"\n",
    "        sentences = []\n",
    "        \n",
    "        for keyword in required_keywords[:num_sentences]:\n",
    "            sentence_templates = [\n",
    "                f\"The concept of {keyword} is fundamental to understanding the field.\",\n",
    "                f\"Recent research on {keyword} has yielded significant insights.\",\n",
    "                f\"Applications of {keyword} are expanding across various domains.\",\n",
    "                f\"The importance of {keyword} cannot be overstated in modern studies.\"\n",
    "            ]\n",
    "            sentences.append(random.choice(sentence_templates))\n",
    "        \n",
    "        # Fill remaining sentences if needed\n",
    "        while len(sentences) < num_sentences:\n",
    "            general_sentences = [\n",
    "                \"Further investigation is needed to fully understand these phenomena.\",\n",
    "                \"The implications of these findings are far-reaching.\",\n",
    "                \"Continued research will likely reveal additional insights.\"\n",
    "            ]\n",
    "            sentences.append(random.choice(general_sentences))\n",
    "        \n",
    "        return ' '.join(sentences[:num_sentences])\n",
    "\n",
    "# Test conditional generation\n",
    "print(\"Conditional Text Generation:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "conditional_gen = ConditionalGenerator()\n",
    "\n",
    "# Topic-based generation\n",
    "print(\"\\n1. Topic-based Generation:\")\n",
    "for topic in ['technology', 'science']:\n",
    "    generated = conditional_gen.generate_by_topic(topic, num_sentences=2)\n",
    "    print(f\"\\n{topic.title()}: {generated}\")\n",
    "\n",
    "# Length-constrained generation\n",
    "print(\"\\n2. Length-constrained Generation:\")\n",
    "short_text = conditional_gen.generate_with_length_constraint('technology', target_length=30)\n",
    "long_text = conditional_gen.generate_with_length_constraint('science', target_length=60)\n",
    "\n",
    "print(f\"\\nShort (30 words): {short_text} ({len(short_text.split())} words)\")\n",
    "print(f\"\\nLong (60 words): {long_text} ({len(long_text.split())} words)\")\n",
    "\n",
    "# Keyword-based generation\n",
    "print(\"\\n3. Keyword-based Generation:\")\n",
    "required_keywords = ['machine learning', 'neural networks', 'algorithms']\n",
    "keyword_text = conditional_gen.generate_with_keywords(required_keywords)\n",
    "print(f\"\\nWith keywords {required_keywords}:\\n{keyword_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation"
   },
   "source": [
    "## Text Generation Evaluation\n",
    "\n",
    "Methods to evaluate the quality of generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluation_metrics"
   },
   "outputs": [],
   "source": [
    "def evaluate_text_quality(texts):\n",
    "    \"\"\"Evaluate various aspects of generated text quality\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for text in texts:\n",
    "        words = word_tokenize(text.lower())\n",
    "        words = [word for word in words if word.isalnum()]\n",
    "        \n",
    "        sentences = sent_tokenize(text)\n",
    "        \n",
    "        # Basic metrics\n",
    "        word_count = len(words)\n",
    "        sentence_count = len(sentences)\n",
    "        unique_words = len(set(words))\n",
    "        \n",
    "        # Lexical diversity (Type-Token Ratio)\n",
    "        ttr = unique_words / word_count if word_count > 0 else 0\n",
    "        \n",
    "        # Average sentence length\n",
    "        avg_sentence_length = word_count / sentence_count if sentence_count > 0 else 0\n",
    "        \n",
    "        # Repetition analysis\n",
    "        word_freq = Counter(words)\n",
    "        repeated_words = sum(1 for count in word_freq.values() if count > 1)\n",
    "        repetition_ratio = repeated_words / unique_words if unique_words > 0 else 0\n",
    "        \n",
    "        # Readability (simple approximation)\n",
    "        long_words = sum(1 for word in words if len(word) > 6)\n",
    "        long_word_ratio = long_words / word_count if word_count > 0 else 0\n",
    "        \n",
    "        results.append({\n",
    "            'text': text[:100] + '...' if len(text) > 100 else text,\n",
    "            'word_count': word_count,\n",
    "            'sentence_count': sentence_count,\n",
    "            'unique_words': unique_words,\n",
    "            'lexical_diversity': ttr,\n",
    "            'avg_sentence_length': avg_sentence_length,\n",
    "            'repetition_ratio': repetition_ratio,\n",
    "            'long_word_ratio': long_word_ratio\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def compare_generation_methods(prompt=\"Artificial intelligence\"):\n",
    "    \"\"\"Compare different text generation methods\"\"\"\n",
    "    generated_texts = {}\n",
    "    \n",
    "    # N-gram generation\n",
    "    if 2 in models:\n",
    "        ngram_text = models[2].generate_text(max_length=30)\n",
    "        generated_texts['2-gram'] = prompt + \" \" + ngram_text\n",
    "    \n",
    "    # Markov chain generation\n",
    "    if 3 in markov_models:\n",
    "        markov_text = markov_models[3].generate_text(length=100, seed=prompt)\n",
    "        generated_texts['Markov'] = markov_text[:150]  # Limit length\n",
    "    \n",
    "    # Conditional generation\n",
    "    conditional_text = conditional_gen.generate_by_topic('technology', num_sentences=2)\n",
    "    generated_texts['Conditional'] = conditional_text\n",
    "    \n",
    "    # Transformer generation (if available)\n",
    "    if generator:\n",
    "        transformer_results = transformer_text_generation(prompt, max_length=60, num_return_sequences=1)\n",
    "        if transformer_results:\n",
    "            generated_texts['Transformer'] = transformer_results[0]\n",
    "    \n",
    "    return generated_texts\n",
    "\n",
    "# Compare generation methods\n",
    "print(\"Text Generation Method Comparison:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "comparison_texts = compare_generation_methods()\n",
    "\n",
    "# Evaluate all generated texts\n",
    "all_texts = list(comparison_texts.values())\n",
    "evaluation_results = evaluate_text_quality(all_texts)\n",
    "\n",
    "# Display results\n",
    "methods = list(comparison_texts.keys())\n",
    "for method, result in zip(methods, evaluation_results):\n",
    "    print(f\"\\n{method}:\")\n",
    "    print(f\"  Text: {result['text']}\")\n",
    "    print(f\"  Words: {result['word_count']}, Sentences: {result['sentence_count']}\")\n",
    "    print(f\"  Lexical Diversity: {result['lexical_diversity']:.3f}\")\n",
    "    print(f\"  Avg Sentence Length: {result['avg_sentence_length']:.1f}\")\n",
    "    print(f\"  Repetition Ratio: {result['repetition_ratio']:.3f}\")\n",
    "\n",
    "# Visualize evaluation metrics\n",
    "if len(evaluation_results) > 1:\n",
    "    metrics = ['lexical_diversity', 'avg_sentence_length', 'repetition_ratio', 'long_word_ratio']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        values = [result[metric] for result in evaluation_results]\n",
    "        axes[i].bar(methods, values)\n",
    "        axes[i].set_title(metric.replace('_', ' ').title())\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "applications"
   },
   "source": [
    "## Real-World Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "applications_demo"
   },
   "outputs": [],
   "source": [
    "# Application 1: Content Creation Assistant\n",
    "def content_creation_assistant(topic, content_type, length='medium'):\n",
    "    \"\"\"Generate content for different purposes\"\"\"\n",
    "    length_settings = {\n",
    "        'short': 30,\n",
    "        'medium': 60,\n",
    "        'long': 100\n",
    "    }\n",
    "    \n",
    "    target_length = length_settings.get(length, 60)\n",
    "    \n",
    "    if content_type == 'blog_intro':\n",
    "        intro_templates = [\n",
    "            f\"In today's rapidly evolving world, {topic} has become increasingly important.\",\n",
    "            f\"The field of {topic} is experiencing unprecedented growth and innovation.\",\n",
    "            f\"Understanding {topic} is crucial for anyone interested in modern technology.\"\n",
    "        ]\n",
    "        base_text = random.choice(intro_templates)\n",
    "        \n",
    "    elif content_type == 'product_description':\n",
    "        desc_templates = [\n",
    "            f\"Our innovative {topic} solution offers cutting-edge features and reliability.\",\n",
    "            f\"Experience the future with our advanced {topic} technology platform.\",\n",
    "            f\"Discover how our {topic} product can transform your workflow and productivity.\"\n",
    "        ]\n",
    "        base_text = random.choice(desc_templates)\n",
    "        \n",
    "    elif content_type == 'educational':\n",
    "        edu_templates = [\n",
    "            f\"Learning about {topic} provides valuable insights into modern scientific principles.\",\n",
    "            f\"The study of {topic} encompasses various disciplines and methodologies.\",\n",
    "            f\"Students exploring {topic} will gain practical knowledge and theoretical understanding.\"\n",
    "        ]\n",
    "        base_text = random.choice(edu_templates)\n",
    "    \n",
    "    else:\n",
    "        base_text = f\"The topic of {topic} is worth exploring in detail.\"\n",
    "    \n",
    "    # Extend with conditional generation\n",
    "    if topic.lower() in ['technology', 'science']:\n",
    "        extended_text = conditional_gen.generate_with_length_constraint(\n",
    "            topic.lower(), target_length\n",
    "        )\n",
    "        return base_text + \" \" + extended_text\n",
    "    else:\n",
    "        return base_text\n",
    "\n",
    "# Application 2: Creative Writing Assistant\n",
    "def creative_writing_prompt(genre, elements):\n",
    "    \"\"\"Generate creative writing prompts and story starters\"\"\"\n",
    "    \n",
    "    genre_settings = {\n",
    "        'sci-fi': {\n",
    "            'settings': ['space station', 'alien planet', 'future city', 'research facility'],\n",
    "            'themes': ['time travel', 'artificial intelligence', 'genetic engineering', 'space exploration']\n",
    "        },\n",
    "        'mystery': {\n",
    "            'settings': ['old mansion', 'small town', 'university campus', 'corporate office'],\n",
    "            'themes': ['missing person', 'stolen artifact', 'corporate espionage', 'family secret']\n",
    "        },\n",
    "        'fantasy': {\n",
    "            'settings': ['magical forest', 'ancient castle', 'mystical island', 'enchanted city'],\n",
    "            'themes': ['quest for power', 'ancient prophecy', 'magical artifact', 'hidden realm']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if genre not in genre_settings:\n",
    "        return \"Genre not supported\"\n",
    "    \n",
    "    setting = random.choice(genre_settings[genre]['settings'])\n",
    "    theme = random.choice(genre_settings[genre]['themes'])\n",
    "    \n",
    "    # Create story starter\n",
    "    starters = [\n",
    "        f\"In the {setting}, a discovery about {theme} changes everything.\",\n",
    "        f\"The {setting} holds secrets related to {theme} that few understand.\",\n",
    "        f\"When {theme} becomes a reality in the {setting}, unexpected challenges arise.\"\n",
    "    ]\n",
    "    \n",
    "    story_starter = random.choice(starters)\n",
    "    \n",
    "    # Add character and conflict elements if provided\n",
    "    if elements:\n",
    "        element_text = f\" The story involves {', '.join(elements)}.\"\n",
    "        story_starter += element_text\n",
    "    \n",
    "    return story_starter\n",
    "\n",
    "# Application 3: Email Template Generator\n",
    "def generate_email_template(email_type, recipient_type, tone='professional'):\n",
    "    \"\"\"Generate email templates for different purposes\"\"\"\n",
    "    \n",
    "    tone_modifiers = {\n",
    "        'professional': 'formal and respectful',\n",
    "        'friendly': 'warm and approachable',\n",
    "        'urgent': 'direct and action-oriented'\n",
    "    }\n",
    "    \n",
    "    templates = {\n",
    "        'follow_up': {\n",
    "            'subject': 'Following up on our previous discussion',\n",
    "            'body': 'I hope this email finds you well. I wanted to follow up on our recent conversation regarding [TOPIC]. Please let me know if you need any additional information.'\n",
    "        },\n",
    "        'introduction': {\n",
    "            'subject': 'Introduction and collaboration opportunity',\n",
    "            'body': 'I am reaching out to introduce myself and explore potential collaboration opportunities. I believe our organizations share common goals and could benefit from working together.'\n",
    "        },\n",
    "        'meeting_request': {\n",
    "            'subject': 'Meeting request to discuss [TOPIC]',\n",
    "            'body': 'I would like to schedule a meeting to discuss [TOPIC] in more detail. Please let me know your availability for the coming week.'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if email_type not in templates:\n",
    "        return \"Email type not supported\"\n",
    "    \n",
    "    template = templates[email_type]\n",
    "    \n",
    "    # Customize based on recipient and tone\n",
    "    greeting = {\n",
    "        'client': 'Dear valued client',\n",
    "        'colleague': 'Hello',\n",
    "        'vendor': 'Dear partner'\n",
    "    }.get(recipient_type, 'Hello')\n",
    "    \n",
    "    closing = {\n",
    "        'professional': 'Best regards',\n",
    "        'friendly': 'Best wishes',\n",
    "        'urgent': 'Thank you for your prompt attention'\n",
    "    }.get(tone, 'Best regards')\n",
    "    \n",
    "    full_email = f\"Subject: {template['subject']}\\n\\n{greeting},\\n\\n{template['body']}\\n\\n{closing},\\n[Your Name]\"\n",
    "    \n",
    "    return full_email\n",
    "\n",
    "# Test applications\n",
    "print(\"Real-World Text Generation Applications:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Content creation\n",
    "print(\"\\n1. Content Creation Assistant:\")\n",
    "blog_intro = content_creation_assistant('artificial intelligence', 'blog_intro', 'medium')\n",
    "product_desc = content_creation_assistant('machine learning', 'product_description', 'short')\n",
    "\n",
    "print(f\"\\nBlog Introduction:\\n{blog_intro}\")\n",
    "print(f\"\\nProduct Description:\\n{product_desc}\")\n",
    "\n",
    "# Creative writing\n",
    "print(\"\\n2. Creative Writing Assistant:\")\n",
    "sci_fi_prompt = creative_writing_prompt('sci-fi', ['android scientist', 'quantum computer'])\n",
    "mystery_prompt = creative_writing_prompt('mystery', ['detective', 'old diary'])\n",
    "\n",
    "print(f\"\\nSci-Fi Prompt: {sci_fi_prompt}\")\n",
    "print(f\"\\nMystery Prompt: {mystery_prompt}\")\n",
    "\n",
    "# Email templates\n",
    "print(\"\\n3. Email Template Generator:\")\n",
    "follow_up_email = generate_email_template('follow_up', 'client', 'professional')\n",
    "meeting_email = generate_email_template('meeting_request', 'colleague', 'friendly')\n",
    "\n",
    "print(f\"\\nFollow-up Email:\\n{follow_up_email}\")\n",
    "print(f\"\\nMeeting Request Email:\\n{meeting_email}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exercises"
   },
   "source": [
    "## Exercises\n",
    "\n",
    "1. **Style Transfer**: Modify text generation to mimic different writing styles\n",
    "2. **Dialogue Generation**: Create conversational text between multiple speakers\n",
    "3. **Poetry Generation**: Implement rhyme and meter constraints\n",
    "4. **Code Generation**: Generate code comments or simple functions\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Multiple approaches available**: From simple n-grams to sophisticated transformers\n",
    "- **Quality vs complexity trade-off**: More complex models generally produce better text\n",
    "- **Conditional generation is powerful**: Controlling output with constraints improves usefulness\n",
    "- **Evaluation is challenging**: Automatic metrics don't always capture text quality\n",
    "- **Context length matters**: Longer context generally leads to more coherent text\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "1. **Start simple**: Begin with n-gram models to understand basics\n",
    "2. **Use appropriate models**: Match model complexity to your quality needs\n",
    "3. **Control generation**: Use temperature, top-p, and other parameters\n",
    "4. **Evaluate thoroughly**: Use both automatic metrics and human evaluation\n",
    "5. **Consider ethics**: Be aware of potential biases and harmful content\n",
    "\n",
    "## Applications\n",
    "\n",
    "- **Content creation**: Blog posts, product descriptions, marketing copy\n",
    "- **Creative writing**: Story prompts, poetry, character development\n",
    "- **Code generation**: Documentation, comments, simple functions\n",
    "- **Chatbots**: Conversational AI and virtual assistants\n",
    "- **Data augmentation**: Generate training data for other NLP tasks\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Learn about fine-tuning pre-trained models\n",
    "- Explore controllable generation techniques\n",
    "- Study evaluation metrics like BLEU, ROUGE, and perplexity\n",
    "- Practice with different domains and writing styles\n",
    "- Learn about ethical considerations in text generation\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [GPT-2 Paper](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n",
    "- [Hugging Face Text Generation](https://huggingface.co/models?pipeline_tag=text-generation)\n",
    "- [The Illustrated GPT-2](http://jalammar.github.io/illustrated-gpt2/)\n",
    "- [OpenAI API Documentation](https://platform.openai.com/docs/)\n",
    "- [Language Model Evaluation Harness](https://github.com/EleutherAI/lm-evaluation-harness)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}