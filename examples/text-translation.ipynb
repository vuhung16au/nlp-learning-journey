{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "translation_title"
   },
   "source": [
    "# Text Translation in Natural Language Processing\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vuhung16au/nlp-learning-journey/blob/main/examples/text-translation.ipynb)\n",
    "\n",
    "## Overview\n",
    "\n",
    "Text translation is the task of automatically converting text from one language to another while preserving meaning, style, and context. Modern approaches use neural machine translation with transformer architectures.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Translation approaches and evolution\n",
    "- Using pre-trained translation models\n",
    "- Transformer-based translation\n",
    "- Evaluation metrics (BLEU, METEOR)\n",
    "- Multilingual models\n",
    "- Translation quality assessment\n",
    "- Real-world applications\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Basic understanding of Python, NLP concepts, and sequence-to-sequence models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup"
   },
   "outputs": [],
   "source": [
    "# Environment Detection and Setup\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Detect the runtime environment\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "IS_LOCAL = not (IS_COLAB or IS_KAGGLE)\n",
    "\n",
    "print(f\"Environment detected:\")\n",
    "print(f\"  - Local: {IS_LOCAL}\")\n",
    "print(f\"  - Google Colab: {IS_COLAB}\")\n",
    "print(f\"  - Kaggle: {IS_KAGGLE}\")\n",
    "\n",
    "# Platform-specific system setup\n",
    "if IS_COLAB:\n",
    "    print(\"\\nSetting up Google Colab environment...\")\n",
    "    !apt update -qq\n",
    "    !apt install -y -qq libpq-dev\n",
    "elif IS_KAGGLE:\n",
    "    print(\"\\nSetting up Kaggle environment...\")\n",
    "    # Kaggle usually has most packages pre-installed\n",
    "else:\n",
    "    print(\"\\nSetting up local environment...\")\n",
    "\n",
    "# Install required packages for this notebook\n",
    "required_packages = [\n",
    "    \"transformers\",\n",
    "    \"torch\",\n",
    "    \"sacrebleu\",\n",
    "    \"pandas\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"langdetect\"\n",
    "]\n",
    "\n",
    "print(\"\\nInstalling required packages...\")\n",
    "for package in required_packages:\n",
    "    if IS_COLAB or IS_KAGGLE:\n",
    "        !pip install -q {package}\n",
    "    else:\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package], \n",
    "                      capture_output=True)\n",
    "    print(f\"âœ“ {package}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "\n",
    "# Translation libraries\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "import sacrebleu\n",
    "from langdetect import detect, LangDetectError\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Language code mappings\n",
    "LANGUAGE_CODES = {\n",
    "    'english': 'en',\n",
    "    'vietnamese': 'vi',\n",
    "    'spanish': 'es', \n",
    "    'french': 'fr',\n",
    "    'german': 'de',\n",
    "    'italian': 'it',\n",
    "    'portuguese': 'pt',\n",
    "    'russian': 'ru',\n",
    "    'chinese': 'zh',\n",
    "    'japanese': 'ja',\n",
    "    'arabic': 'ar'\n",
    "}\n",
    "\n",
    "LANGUAGE_NAMES = {v: k for k, v in LANGUAGE_CODES.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sample_texts"
   },
   "source": [
    "## Sample Texts for Translation\n",
    "\n",
    "Let's create sample texts in different languages for translation experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_samples"
   },
   "outputs": [],
   "source": [
    "# Sample texts in different languages\n",
    "sample_texts = {\n",
    "    'en': [\n",
    "        \"Hello, how are you today?\",\n",
    "        \"The weather is beautiful this morning.\",\n",
    "        \"Artificial intelligence is changing the world.\",\n",
    "        \"I would like to book a table for two people.\",\n",
    "        \"Science and technology advance human knowledge.\"\n",
    "    ],\n",
    "    'vi': [\n",
    "        \"Xin chÃ o, báº¡n khá»e khÃ´ng hÃ´m nay?\",\n",
    "        \"Thá»i tiáº¿t Ä‘áº¹p vÃ o sÃ¡ng nay.\",\n",
    "        \"TrÃ­ tuá»‡ nhÃ¢n táº¡o Ä‘ang thay Ä‘á»•i tháº¿ giá»›i.\",\n",
    "        \"TÃ´i muá»‘n Ä‘áº·t bÃ n cho hai ngÆ°á»i.\",\n",
    "        \"Khoa há»c vÃ  cÃ´ng nghá»‡ nÃ¢ng cao kiáº¿n thá»©c con ngÆ°á»i.\"\n",
    "    ],\n",
    "    'es': [\n",
    "        \"Hola, Â¿cÃ³mo estÃ¡s hoy?\",\n",
    "        \"El clima estÃ¡ hermoso esta maÃ±ana.\",\n",
    "        \"La inteligencia artificial estÃ¡ cambiando el mundo.\",\n",
    "        \"Me gustarÃ­a reservar una mesa para dos personas.\",\n",
    "        \"La ciencia y la tecnologÃ­a avanzan el conocimiento humano.\"\n",
    "    ],\n",
    "    'fr': [\n",
    "        \"Bonjour, comment allez-vous aujourd'hui?\",\n",
    "        \"Le temps est magnifique ce matin.\",\n",
    "        \"L'intelligence artificielle change le monde.\",\n",
    "        \"J'aimerais rÃ©server une table pour deux personnes.\",\n",
    "        \"La science et la technologie font progresser les connaissances humaines.\"\n",
    "    ],\n",
    "    'de': [\n",
    "        \"Hallo, wie geht es dir heute?\",\n",
    "        \"Das Wetter ist heute Morgen schÃ¶n.\",\n",
    "        \"KÃ¼nstliche Intelligenz verÃ¤ndert die Welt.\",\n",
    "        \"Ich mÃ¶chte einen Tisch fÃ¼r zwei Personen reservieren.\",\n",
    "        \"Wissenschaft und Technologie fÃ¶rdern das menschliche Wissen.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Sample Texts for Translation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for lang_code, texts in sample_texts.items():\n",
    "    lang_name = LANGUAGE_NAMES.get(lang_code, lang_code).title()\n",
    "    print(f\"\\n{lang_name} ({lang_code}):\")\n",
    "    for i, text in enumerate(texts[:3], 1):\n",
    "        print(f\"  {i}. {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "language_detection"
   },
   "source": [
    "## Language Detection\n",
    "\n",
    "Before translation, we often need to detect the source language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "detect_language"
   },
   "outputs": [],
   "source": [
    "def detect_language_with_confidence(text):\n",
    "    \"\"\"Detect language with confidence estimation\"\"\"\n",
    "    try:\n",
    "        from langdetect import detect_langs\n",
    "        detections = detect_langs(text)\n",
    "        \n",
    "        # Get the most likely language\n",
    "        best_detection = detections[0]\n",
    "        \n",
    "        return {\n",
    "            'language': best_detection.lang,\n",
    "            'confidence': best_detection.prob,\n",
    "            'all_detections': [(d.lang, d.prob) for d in detections]\n",
    "        }\n",
    "    except LangDetectError:\n",
    "        return {\n",
    "            'language': 'unknown',\n",
    "            'confidence': 0.0,\n",
    "            'all_detections': []\n",
    "        }\n",
    "    except ImportError:\n",
    "        # Fallback if langdetect not available\n",
    "        try:\n",
    "            lang = detect(text)\n",
    "            return {\n",
    "                'language': lang,\n",
    "                'confidence': 0.8,  # Assume reasonable confidence\n",
    "                'all_detections': [(lang, 0.8)]\n",
    "            }\n",
    "        except:\n",
    "            return {\n",
    "                'language': 'unknown',\n",
    "                'confidence': 0.0,\n",
    "                'all_detections': []\n",
    "            }\n",
    "\n",
    "# Test language detection\n",
    "print(\"Language Detection Results:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "test_texts = [\n",
    "    (\"Hello, how are you?\", \"English\"),\n",
    "    (\"Bonjour, comment allez-vous?\", \"French\"),\n",
    "    (\"Hola, Â¿cÃ³mo estÃ¡s?\", \"Spanish\"),\n",
    "    (\"Guten Tag, wie geht es Ihnen?\", \"German\"),\n",
    "    (\"Artificial intelligence is the future\", \"English\")\n",
    "]\n",
    "\n",
    "detection_results = []\n",
    "for text, expected_lang in test_texts:\n",
    "    result = detect_language_with_confidence(text)\n",
    "    detection_results.append(result)\n",
    "    \n",
    "    detected_lang = LANGUAGE_NAMES.get(result['language'], result['language'])\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"Expected: {expected_lang}\")\n",
    "    print(f\"Detected: {detected_lang.title()} ({result['language']})\")\n",
    "    print(f\"Confidence: {result['confidence']:.3f}\")\n",
    "    \n",
    "    if len(result['all_detections']) > 1:\n",
    "        alternatives = result['all_detections'][1:3]  # Show top 2 alternatives\n",
    "        alt_str = \", \".join([f\"{lang} ({prob:.2f})\" for lang, prob in alternatives])\n",
    "        print(f\"Alternatives: {alt_str}\")\n",
    "\n",
    "# Calculate detection accuracy\n",
    "correct_detections = 0\n",
    "total_detections = len(test_texts)\n",
    "\n",
    "expected_codes = {'english': 'en', 'french': 'fr', 'spanish': 'es', 'german': 'de'}\n",
    "for i, (_, expected_lang) in enumerate(test_texts):\n",
    "    expected_code = expected_codes.get(expected_lang.lower(), 'unknown')\n",
    "    detected_code = detection_results[i]['language']\n",
    "    \n",
    "    if expected_code == detected_code:\n",
    "        correct_detections += 1\n",
    "\n",
    "accuracy = correct_detections / total_detections\n",
    "print(f\"\\nLanguage Detection Accuracy: {accuracy:.1%} ({correct_detections}/{total_detections})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "transformer_translation"
   },
   "source": [
    "## Transformer-Based Translation\n",
    "\n",
    "Using pre-trained transformer models for high-quality translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "translation_models"
   },
   "outputs": [],
   "source": [
    "# Initialize translation pipelines\n",
    "translation_pipelines = {}\n",
    "\n",
    "def load_translation_pipeline(source_lang, target_lang):\n",
    "    \"\"\"Load translation pipeline for specific language pair\"\"\"\n",
    "    model_name_map = {\n",
    "        ('en', 'es'): 'Helsinki-NLP/opus-mt-en-es',\n",
    "        ('en', 'fr'): 'Helsinki-NLP/opus-mt-en-fr', \n",
    "        ('en', 'de'): 'Helsinki-NLP/opus-mt-en-de',\n",
    "        ('es', 'en'): 'Helsinki-NLP/opus-mt-es-en',\n",
    "        ('fr', 'en'): 'Helsinki-NLP/opus-mt-fr-en',\n",
    "        ('de', 'en'): 'Helsinki-NLP/opus-mt-de-en'\n",
    "    }\n",
    "    \n",
    "    pair = (source_lang, target_lang)\n",
    "    if pair in model_name_map:\n",
    "        try:\n",
    "            model_name = model_name_map[pair]\n",
    "            pipeline_obj = pipeline('translation', model=model_name)\n",
    "            return pipeline_obj\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load {pair} model: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Try generic multilingual model\n",
    "    try:\n",
    "        pipeline_obj = pipeline('translation', \n",
    "                               model='facebook/m2m100_418M', \n",
    "                               src_lang=source_lang, \n",
    "                               tgt_lang=target_lang)\n",
    "        return pipeline_obj\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load multilingual model for {pair}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load some common translation pipelines\n",
    "common_pairs = [('en', 'es'), ('en', 'fr'), ('es', 'en'), ('fr', 'en')]\n",
    "\n",
    "print(\"Loading Translation Models:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for source, target in common_pairs:\n",
    "    print(f\"\\nLoading {source} -> {target} model...\")\n",
    "    pipeline_obj = load_translation_pipeline(source, target)\n",
    "    if pipeline_obj:\n",
    "        translation_pipelines[(source, target)] = pipeline_obj\n",
    "        print(f\"âœ“ Successfully loaded {source} -> {target}\")\n",
    "    else:\n",
    "        print(f\"âœ— Failed to load {source} -> {target}\")\n",
    "\n",
    "print(f\"\\nLoaded {len(translation_pipelines)} translation models\")\n",
    "\n",
    "def translate_text(text, source_lang, target_lang, max_length=512):\n",
    "    \"\"\"Translate text using available models\"\"\"\n",
    "    pair = (source_lang, target_lang)\n",
    "    \n",
    "    if pair in translation_pipelines:\n",
    "        try:\n",
    "            result = translation_pipelines[pair](text, max_length=max_length)\n",
    "            if isinstance(result, list) and len(result) > 0:\n",
    "                return result[0]['translation_text']\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"Translation error: {e}\"\n",
    "    else:\n",
    "        return f\"No model available for {source_lang} -> {target_lang}\"\n",
    "\n",
    "# Test translation\n",
    "if translation_pipelines:\n",
    "    print(\"\\nTranslation Examples:\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    test_translations = [\n",
    "        (\"Hello, how are you today?\", \"en\", \"es\"),\n",
    "        (\"The weather is beautiful.\", \"en\", \"fr\"),\n",
    "        (\"Hola, Â¿cÃ³mo estÃ¡s?\", \"es\", \"en\"),\n",
    "        (\"Bonjour, comment allez-vous?\", \"fr\", \"en\")\n",
    "    ]\n",
    "    \n",
    "    for text, src_lang, tgt_lang in test_translations:\n",
    "        if (src_lang, tgt_lang) in translation_pipelines:\n",
    "            translation = translate_text(text, src_lang, tgt_lang)\n",
    "            src_name = LANGUAGE_NAMES.get(src_lang, src_lang)\n",
    "            tgt_name = LANGUAGE_NAMES.get(tgt_lang, tgt_lang)\n",
    "            \n",
    "            print(f\"\\n{src_name.title()} -> {tgt_name.title()}:\")\n",
    "            print(f\"  Original: {text}\")\n",
    "            print(f\"  Translation: {translation}\")\nelse:\n",
    "    print(\"No translation models available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "multilingual_models"
   },
   "source": [
    "## Multilingual Translation Models\n",
    "\n",
    "Using models that can translate between multiple language pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "multilingual_translation"
   },
   "outputs": [],
   "source": [
    "class MultilingualTranslator:\n",
    "    def __init__(self):\n",
    "        self.pipeline = None\n",
    "        self.supported_languages = set()\n",
    "        self.load_model()\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"Load multilingual translation model\"\"\"\n",
    "        try:\n",
    "            # Try to load M2M100 model (many-to-many multilingual)\n",
    "            self.pipeline = pipeline('translation', model='facebook/m2m100_418M')\n",
    "            \n",
    "            # M2M100 supported languages (subset)\n",
    "            self.supported_languages = {\n",
    "                'en', 'es', 'fr', 'de', 'it', 'pt', 'ru', 'zh', 'ja', 'ar', 'hi', 'ko'\n",
    "            }\n",
    "            \n",
    "            print(\"Loaded M2M100 multilingual model\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Could not load multilingual model: {e}\")\n",
    "            print(\"Using fallback approach...\")\n",
    "            \n",
    "            # Fallback: use available bilateral models\n",
    "            self.supported_languages = {'en', 'es', 'fr', 'de'}\n",
    "    \n",
    "    def translate(self, text, source_lang, target_lang):\n",
    "        \"\"\"Translate text between any supported language pair\"\"\"\n",
    "        if source_lang not in self.supported_languages:\n",
    "            return f\"Source language '{source_lang}' not supported\"\n",
    "        \n",
    "        if target_lang not in self.supported_languages:\n",
    "            return f\"Target language '{target_lang}' not supported\"\n",
    "        \n",
    "        if source_lang == target_lang:\n",
    "            return text\n",
    "        \n",
    "        if self.pipeline:\n",
    "            try:\n",
    "                # For M2M100, we need to set source and target languages\n",
    "                result = self.pipeline(text, src_lang=source_lang, tgt_lang=target_lang)\n",
    "                if isinstance(result, list) and len(result) > 0:\n",
    "                    return result[0]['translation_text']\n",
    "                return str(result)\n",
    "            except Exception as e:\n",
    "                return f\"Translation error: {e}\"\n",
    "        else:\n",
    "            # Fallback to bilateral models\n",
    "            return translate_text(text, source_lang, target_lang)\n",
    "    \n",
    "    def get_supported_languages(self):\n",
    "        \"\"\"Get list of supported languages\"\"\"\n",
    "        return sorted(list(self.supported_languages))\n",
    "    \n",
    "    def translate_to_multiple_languages(self, text, source_lang, target_langs):\n",
    "        \"\"\"Translate text to multiple target languages\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for target_lang in target_langs:\n",
    "            if target_lang != source_lang:\n",
    "                translation = self.translate(text, source_lang, target_lang)\n",
    "                results[target_lang] = translation\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Initialize multilingual translator\n",
    "multilingual_translator = MultilingualTranslator()\n",
    "\n",
    "print(f\"\\nSupported languages: {multilingual_translator.get_supported_languages()}\")\n",
    "\n",
    "# Test multilingual translation\n",
    "print(\"\\nMultilingual Translation Examples:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "test_text = \"Hello, welcome to our restaurant!\"\n",
    "source_language = \"en\"\n",
    "target_languages = [\"es\", \"fr\", \"de\"]\n",
    "\n",
    "print(f\"\\nOriginal ({source_language}): {test_text}\")\n",
    "print(\"\\nTranslations:\")\n",
    "\n",
    "translations = multilingual_translator.translate_to_multiple_languages(\n",
    "    test_text, source_language, target_languages\n",
    ")\n",
    "\n",
    "for lang, translation in translations.items():\n",
    "    lang_name = LANGUAGE_NAMES.get(lang, lang)\n",
    "    print(f\"  {lang_name.title()} ({lang}): {translation}\")\n",
    "\n",
    "# Test round-trip translation\n",
    "print(\"\\nRound-trip Translation Test:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "original_text = \"Machine learning is transforming technology.\"\n",
    "intermediate_lang = \"es\"\n",
    "final_lang = \"en\"\n",
    "\n",
    "# Translate EN -> ES -> EN\n",
    "step1 = multilingual_translator.translate(original_text, \"en\", intermediate_lang)\n",
    "step2 = multilingual_translator.translate(step1, intermediate_lang, final_lang)\n",
    "\n",
    "print(f\"Original (EN): {original_text}\")\n",
    "print(f\"Intermediate (ES): {step1}\")\n",
    "print(f\"Back to English: {step2}\")\n",
    "\n",
    "# Calculate similarity (simple word overlap)\n",
    "original_words = set(original_text.lower().split())\n",
    "back_translated_words = set(step2.lower().split())\n",
    "overlap = len(original_words.intersection(back_translated_words))\n",
    "similarity = overlap / len(original_words) if original_words else 0\n",
    "\n",
    "print(f\"Word overlap similarity: {similarity:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation_metrics"
   },
   "source": [
    "## Translation Quality Evaluation\n",
    "\n",
    "Methods to evaluate translation quality using automatic metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "translation_evaluation"
   },
   "outputs": [],
   "source": [
    "def calculate_bleu_score(reference, candidate):\n",
    "    \"\"\"Calculate BLEU score for translation quality\"\"\"\n",
    "    try:\n",
    "        # BLEU expects list of references and single candidate\n",
    "        bleu_score = sacrebleu.sentence_bleu(candidate, [reference])\n",
    "        return bleu_score.score\n",
    "    except Exception as e:\n",
    "        print(f\"BLEU calculation error: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def calculate_simple_metrics(reference, candidate):\n",
    "    \"\"\"Calculate simple translation metrics\"\"\"\n",
    "    # Tokenize\n",
    "    ref_words = reference.lower().split()\n",
    "    cand_words = candidate.lower().split()\n",
    "    \n",
    "    # Length ratio\n",
    "    length_ratio = len(cand_words) / len(ref_words) if ref_words else 0\n",
    "    \n",
    "    # Word overlap (precision and recall)\n",
    "    ref_set = set(ref_words)\n",
    "    cand_set = set(cand_words)\n",
    "    overlap = ref_set.intersection(cand_set)\n",
    "    \n",
    "    precision = len(overlap) / len(cand_set) if cand_set else 0\n",
    "    recall = len(overlap) / len(ref_set) if ref_set else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'length_ratio': length_ratio,\n",
    "        'word_precision': precision,\n",
    "        'word_recall': recall,\n",
    "        'word_f1': f1\n",
    "    }\n",
    "\n",
    "def evaluate_translation_quality(test_cases):\n",
    "    \"\"\"Evaluate translation quality on multiple test cases\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for case in test_cases:\n",
    "        source_text = case['source']\n",
    "        reference = case['reference']\n",
    "        candidate = case['candidate']\n",
    "        \n",
    "        # Calculate metrics\n",
    "        bleu = calculate_bleu_score(reference, candidate)\n",
    "        simple_metrics = calculate_simple_metrics(reference, candidate)\n",
    "        \n",
    "        result = {\n",
    "            'source': source_text,\n",
    "            'reference': reference,\n",
    "            'candidate': candidate,\n",
    "            'bleu_score': bleu,\n",
    "            **simple_metrics\n",
    "        }\n",
    "        \n",
    "        results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Create test cases for evaluation\n",
    "test_cases = [\n",
    "    {\n",
    "        'source': 'Hello, how are you?',\n",
    "        'reference': 'Hola, Â¿cÃ³mo estÃ¡s?',\n",
    "        'candidate': multilingual_translator.translate('Hello, how are you?', 'en', 'es')\n",
    "    },\n",
    "    {\n",
    "        'source': 'The weather is nice today.',\n",
    "        'reference': 'El clima estÃ¡ agradable hoy.',\n",
    "        'candidate': multilingual_translator.translate('The weather is nice today.', 'en', 'es')\n",
    "    },\n",
    "    {\n",
    "        'source': 'I love reading books.',\n",
    "        'reference': 'Me encanta leer libros.',\n",
    "        'candidate': multilingual_translator.translate('I love reading books.', 'en', 'es')\n",
    "    }\n",
    "]\n",
    "\n",
    "# Evaluate translations\n",
    "evaluation_results = evaluate_translation_quality(test_cases)\n",
    "\n",
    "print(\"Translation Quality Evaluation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "total_bleu = 0\n",
    "total_f1 = 0\n",
    "valid_results = 0\n",
    "\n",
    "for i, result in enumerate(evaluation_results, 1):\n",
    "    print(f\"\\nTest Case {i}:\")\n",
    "    print(f\"  Source: {result['source']}\")\n",
    "    print(f\"  Reference: {result['reference']}\")\n",
    "    print(f\"  Translation: {result['candidate']}\")\n",
    "    \n",
    "    if not result['candidate'].startswith('Translation error'):\n",
    "        print(f\"  BLEU Score: {result['bleu_score']:.2f}\")\n",
    "        print(f\"  Word F1: {result['word_f1']:.3f}\")\n",
    "        print(f\"  Length Ratio: {result['length_ratio']:.2f}\")\n",
    "        \n",
    "        total_bleu += result['bleu_score']\n",
    "        total_f1 += result['word_f1']\n",
    "        valid_results += 1\n",
    "    else:\n",
    "        print(f\"  Error: {result['candidate']}\")\n",
    "\n",
    "if valid_results > 0:\n",
    "    avg_bleu = total_bleu / valid_results\n",
    "    avg_f1 = total_f1 / valid_results\n",
    "    \n",
    "    print(f\"\\nOverall Performance:\")\n",
    "    print(f\"  Average BLEU Score: {avg_bleu:.2f}\")\n",
    "    print(f\"  Average Word F1: {avg_f1:.3f}\")\n",
    "    print(f\"  Valid Translations: {valid_results}/{len(test_cases)}\")\n",
    "\n",
    "# Visualize evaluation results\n",
    "if valid_results > 0:\n",
    "    valid_results = [r for r in evaluation_results if not r['candidate'].startswith('Translation error')]\n",
    "    \n",
    "    if len(valid_results) >= 2:\n",
    "        metrics = ['bleu_score', 'word_f1', 'word_precision', 'word_recall']\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        axes = axes.ravel()\n",
    "        \n",
    "        for i, metric in enumerate(metrics):\n",
    "            values = [r[metric] for r in valid_results]\n",
    "            test_names = [f\"Test {j+1}\" for j in range(len(valid_results))]\n",
    "            \n",
    "            axes[i].bar(test_names, values)\n",
    "            axes[i].set_title(metric.replace('_', ' ').title())\n",
    "            axes[i].set_ylim(0, 1)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "translation_challenges"
   },
   "source": [
    "## Translation Challenges and Limitations\n",
    "\n",
    "Exploring common challenges in machine translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "translation_challenges_demo"
   },
   "outputs": [],
   "source": [
    "# Examples of challenging translation scenarios\n",
    "challenging_examples = {\n",
    "    'idioms': {\n",
    "        'source': \"It's raining cats and dogs outside.\",\n",
    "        'challenge': \"Idiomatic expressions don't translate literally\",\n",
    "        'expected_meaning': \"It's raining heavily outside.\"\n",
    "    },\n",
    "    'context_dependent': {\n",
    "        'source': \"The bank is closed.\",\n",
    "        'challenge': \"'Bank' could mean financial institution or river bank\",\n",
    "        'expected_meaning': \"Context determines which meaning is intended\"\n",
    "    },\n",
    "    'cultural_references': {\n",
    "        'source': \"He's a real Einstein.\",\n",
    "        'challenge': \"Cultural references may not translate across cultures\",\n",
    "        'expected_meaning': \"He's very intelligent.\"\n",
    "    },\n",
    "    'wordplay': {\n",
    "        'source': \"Time flies like an arrow; fruit flies like a banana.\",\n",
    "        'challenge': \"Puns and wordplay are difficult to preserve\",\n",
    "        'expected_meaning': \"Humorous play on the word 'flies'\"\n",
    "    },\n",
    "    'formal_informal': {\n",
    "        'source': \"What's up, dude?\",\n",
    "        'challenge': \"Register and formality levels vary across languages\",\n",
    "        'expected_meaning': \"Informal greeting between friends\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Translation Challenges Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for challenge_type, example in challenging_examples.items():\n",
    "    source_text = example['source']\n",
    "    \n",
    "    print(f\"\\n{challenge_type.replace('_', ' ').title()}:\")\n",
    "    print(f\"  Original: {source_text}\")\n",
    "    print(f\"  Challenge: {example['challenge']}\")\n",
    "    \n",
    "    # Try translating to Spanish and back\n",
    "    translation_es = multilingual_translator.translate(source_text, 'en', 'es')\n",
    "    back_translation = multilingual_translator.translate(translation_es, 'es', 'en')\n",
    "    \n",
    "    if not translation_es.startswith('Translation error'):\n",
    "        print(f\"  Spanish: {translation_es}\")\n",
    "        if not back_translation.startswith('Translation error'):\n",
    "            print(f\"  Back to English: {back_translation}\")\n",
    "            \n",
    "            # Check if meaning is preserved\n",
    "            meaning_preserved = \"partially\" if source_text.lower() in back_translation.lower() else \"unclear\"\n",
    "            print(f\"  Meaning preservation: {meaning_preserved}\")\n",
    "    else:\n",
    "        print(f\"  Translation failed: {translation_es}\")\n",
    "\n",
    "# Domain-specific translation challenges\n",
    "print(\"\\n\\nDomain-Specific Challenges:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "domain_examples = {\n",
    "    'Technical': \"The API endpoint returns a JSON response with nested objects.\",\n",
    "    'Medical': \"The patient presents with acute myocardial infarction symptoms.\",\n",
    "    'Legal': \"The party hereby agrees to the terms and conditions stipulated herein.\",\n",
    "    'Literary': \"The crimson sunset painted the sky with ethereal beauty.\"\n",
    "}\n",
    "\n",
    "for domain, text in domain_examples.items():\n",
    "    translation = multilingual_translator.translate(text, 'en', 'fr')\n",
    "    \n",
    "    print(f\"\\n{domain}:\")\n",
    "    print(f\"  English: {text}\")\n",
    "    if not translation.startswith('Translation error'):\n",
    "        print(f\"  French: {translation}\")\n",
    "    else:\n",
    "        print(f\"  Translation issue: {translation}\")\n",
    "\n",
    "# Translation quality factors\n",
    "quality_factors = {\n",
    "    'Fluency': 'How natural and grammatically correct is the translation?',\n",
    "    'Adequacy': 'How much of the source meaning is preserved?',\n",
    "    'Consistency': 'Are similar phrases translated consistently?',\n",
    "    'Style': 'Is the appropriate register and style maintained?',\n",
    "    'Terminology': 'Are domain-specific terms translated correctly?'\n",
    "}\n",
    "\n",
    "print(\"\\n\\nTranslation Quality Factors:\")\n",
    "print(\"=\" * 35)\n",
    "for factor, description in quality_factors.items():\n",
    "    print(f\"\\n{factor}: {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "applications"
   },
   "source": [
    "## Real-World Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "applications_demo"
   },
   "outputs": [],
   "source": [
    "# Application 1: Document Translation Service\n",
    "class DocumentTranslationService:\n",
    "    def __init__(self, translator):\n",
    "        self.translator = translator\n",
    "        self.supported_formats = ['txt', 'simple_html']\n",
    "    \n",
    "    def translate_document(self, content, source_lang, target_lang, format_type='txt'):\n",
    "        \"\"\"Translate document content while preserving structure\"\"\"\n",
    "        if format_type == 'txt':\n",
    "            return self._translate_plain_text(content, source_lang, target_lang)\n",
    "        elif format_type == 'simple_html':\n",
    "            return self._translate_html(content, source_lang, target_lang)\n",
    "        else:\n",
    "            return \"Unsupported format\"\n",
    "    \n",
    "    def _translate_plain_text(self, content, source_lang, target_lang):\n",
    "        \"\"\"Translate plain text paragraph by paragraph\"\"\"\n",
    "        paragraphs = content.split('\\n\\n')\n",
    "        translated_paragraphs = []\n",
    "        \n",
    "        for paragraph in paragraphs:\n",
    "            if paragraph.strip():\n",
    "                translated = self.translator.translate(paragraph.strip(), source_lang, target_lang)\n",
    "                translated_paragraphs.append(translated)\n",
    "            else:\n",
    "                translated_paragraphs.append('')\n",
    "        \n",
    "        return '\\n\\n'.join(translated_paragraphs)\n",
    "    \n",
    "    def _translate_html(self, content, source_lang, target_lang):\n",
    "        \"\"\"Translate HTML content while preserving tags\"\"\"\n",
    "        # Simple approach: extract text between tags and translate\n",
    "        import re\n",
    "        \n",
    "        def translate_match(match):\n",
    "            text = match.group(1)\n",
    "            if text.strip():\n",
    "                return self.translator.translate(text, source_lang, target_lang)\n",
    "            return text\n",
    "        \n",
    "        # Pattern to match text between HTML tags (simplified)\n",
    "        pattern = r'>([^<]+)<'\n",
    "        translated_content = re.sub(pattern, lambda m: f'>{translate_match(m)}<', content)\n",
    "        \n",
    "        return translated_content\n",
    "    \n",
    "    def get_translation_summary(self, original_content, translated_content):\n",
    "        \"\"\"Generate summary of translation\"\"\"\n",
    "        original_words = len(original_content.split())\n",
    "        translated_words = len(translated_content.split())\n",
    "        \n",
    "        return {\n",
    "            'original_word_count': original_words,\n",
    "            'translated_word_count': translated_words,\n",
    "            'length_ratio': translated_words / original_words if original_words > 0 else 0,\n",
    "            'character_count_original': len(original_content),\n",
    "            'character_count_translated': len(translated_content)\n",
    "        }\n",
    "\n",
    "# Application 2: Real-time Chat Translation\n",
    "class ChatTranslationBot:\n",
    "    def __init__(self, translator):\n",
    "        self.translator = translator\n",
    "        self.conversation_history = []\n",
    "        self.user_languages = {}\n",
    "    \n",
    "    def add_user_language(self, user_id, language):\n",
    "        \"\"\"Set preferred language for a user\"\"\"\n",
    "        self.user_languages[user_id] = language\n",
    "    \n",
    "    def process_message(self, message, sender_id, sender_lang=None):\n",
    "        \"\"\"Process and translate message for all participants\"\"\"\n",
    "        # Detect language if not provided\n",
    "        if not sender_lang:\n",
    "            detection = detect_language_with_confidence(message)\n",
    "            sender_lang = detection['language']\n",
    "        \n",
    "        # Store original message\n",
    "        conversation_entry = {\n",
    "            'sender_id': sender_id,\n",
    "            'original_message': message,\n",
    "            'original_language': sender_lang,\n",
    "            'translations': {}\n",
    "        }\n",
    "        \n",
    "        # Translate for each user\n",
    "        for user_id, user_lang in self.user_languages.items():\n",
    "            if user_id != sender_id and user_lang != sender_lang:\n",
    "                translation = self.translator.translate(message, sender_lang, user_lang)\n",
    "                conversation_entry['translations'][user_id] = {\n",
    "                    'language': user_lang,\n",
    "                    'text': translation\n",
    "                }\n",
    "        \n",
    "        self.conversation_history.append(conversation_entry)\n",
    "        return conversation_entry\n",
    "    \n",
    "    def get_message_for_user(self, message_entry, user_id):\n",
    "        \"\"\"Get appropriate message version for specific user\"\"\"\n",
    "        if user_id in message_entry['translations']:\n",
    "            translation_info = message_entry['translations'][user_id]\n",
    "            return f\"[{translation_info['language']}] {translation_info['text']}\"\n",
    "        else:\n",
    "            return f\"[{message_entry['original_language']}] {message_entry['original_message']}\"\n",
    "\n",
    "# Application 3: Website Localization Helper\n",
    "def website_localization_demo(content, target_languages):\n",
    "    \"\"\"Demo of website content localization\"\"\"\n",
    "    \n",
    "    website_content = {\n",
    "        'title': 'Welcome to Our Website',\n",
    "        'navigation': ['Home', 'About', 'Services', 'Contact'],\n",
    "        'main_text': 'We provide innovative solutions for your business needs.',\n",
    "        'call_to_action': 'Get started today!',\n",
    "        'footer': 'Copyright 2024. All rights reserved.'\n",
    "    }\n",
    "    \n",
    "    localized_content = {}\n",
    "    \n",
    "    for lang in target_languages:\n",
    "        localized_content[lang] = {}\n",
    "        \n",
    "        for key, value in website_content.items():\n",
    "            if isinstance(value, list):\n",
    "                # Translate list items\n",
    "                translated_list = []\n",
    "                for item in value:\n",
    "                    translation = multilingual_translator.translate(item, 'en', lang)\n",
    "                    translated_list.append(translation)\n",
    "                localized_content[lang][key] = translated_list\n",
    "            else:\n",
    "                # Translate string\n",
    "                translation = multilingual_translator.translate(value, 'en', lang)\n",
    "                localized_content[lang][key] = translation\n",
    "    \n",
    "    return localized_content\n",
    "\n",
    "# Test applications\n",
    "print(\"Real-World Translation Applications:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test document translation\n",
    "print(\"\\n1. Document Translation Service:\")\n",
    "doc_service = DocumentTranslationService(multilingual_translator)\n",
    "\n",
    "sample_document = \"\"\"\n",
    "Introduction\n",
    "\n",
    "This document contains important information about our services. We offer comprehensive solutions for businesses of all sizes.\n",
    "\n",
    "Our team has extensive experience in the industry. We are committed to providing excellent customer service.\n",
    "\"\"\"\n",
    "\n",
    "translated_doc = doc_service.translate_document(sample_document, 'en', 'es')\n",
    "translation_summary = doc_service.get_translation_summary(sample_document, translated_doc)\n",
    "\n",
    "print(f\"\\nOriginal Document (first 100 chars): {sample_document[:100]}...\")\n",
    "print(f\"Translated Document (first 100 chars): {translated_doc[:100]}...\")\n",
    "print(f\"\\nTranslation Summary:\")\n",
    "for key, value in translation_summary.items():\n",
    "    print(f\"  {key}: {value:.2f}\" if isinstance(value, float) else f\"  {key}: {value}\")\n",
    "\n",
    "# Test chat translation\n",
    "print(\"\\n2. Chat Translation Bot:\")\n",
    "chat_bot = ChatTranslationBot(multilingual_translator)\n",
    "\n",
    "# Set up users with different languages\n",
    "chat_bot.add_user_language('user1', 'en')\n",
    "chat_bot.add_user_language('user2', 'es')\n",
    "chat_bot.add_user_language('user3', 'fr')\n",
    "\n",
    "# Simulate conversation\n",
    "messages = [\n",
    "    ('user1', 'Hello everyone!', 'en'),\n",
    "    ('user2', 'Hola, Â¿cÃ³mo estÃ¡n?', 'es'),\n",
    "    ('user3', 'Bonjour! Comment allez-vous?', 'fr')\n",
    "]\n",
    "\n",
    "print(\"\\nMultilingual Chat Simulation:\")\n",
    "for sender, message, lang in messages:\n",
    "    entry = chat_bot.process_message(message, sender, lang)\n",
    "    \n",
    "    print(f\"\\n{sender} ({lang}): {message}\")\n",
    "    \n",
    "    # Show how each user sees the message\n",
    "    for user_id in chat_bot.user_languages:\n",
    "        if user_id != sender:\n",
    "            user_view = chat_bot.get_message_for_user(entry, user_id)\n",
    "            print(f\"  {user_id} sees: {user_view}\")\n",
    "\n",
    "# Test website localization\n",
    "print(\"\\n3. Website Localization:\")\n",
    "target_langs = ['es', 'fr']\n",
    "localized_site = website_localization_demo(None, target_langs)\n",
    "\n",
    "for lang, content in localized_site.items():\n",
    "    lang_name = LANGUAGE_NAMES.get(lang, lang)\n",
    "    print(f\"\\n{lang_name.title()} ({lang}):\")\n",
    "    print(f\"  Title: {content['title']}\")\n",
    "    print(f\"  Navigation: {content['navigation']}\")\n",
    "    print(f\"  Main Text: {content['main_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exercises"
   },
   "source": [
    "## Exercises\n",
    "\n",
    "1. **Custom Translation Pipeline**: Build a pipeline that handles specific document formats\n",
    "2. **Translation Memory**: Implement a system that reuses previous translations\n",
    "3. **Quality Estimation**: Create a model to predict translation quality without references\n",
    "4. **Domain Adaptation**: Fine-tune models for specific domains (medical, legal, etc.)\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Neural MT is dominant**: Transformer-based models provide state-of-the-art quality\n",
    "- **Context matters**: Longer context generally improves translation quality\n",
    "- **Language detection is crucial**: Accurate source language identification improves results\n",
    "- **Evaluation is challenging**: Automatic metrics don't capture all aspects of quality\n",
    "- **Domain specialization helps**: Models perform better on familiar text types\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "1. **Preprocess carefully**: Clean and normalize text before translation\n",
    "2. **Use appropriate models**: Match model capabilities to your language pairs\n",
    "3. **Consider context**: Provide sufficient context for ambiguous terms\n",
    "4. **Evaluate thoroughly**: Use both automatic metrics and human evaluation\n",
    "5. **Handle errors gracefully**: Plan for translation failures and edge cases\n",
    "\n",
    "## Common Challenges\n",
    "\n",
    "- **Idioms and cultural references**: Don't translate literally across cultures\n",
    "- **Technical terminology**: May require domain-specific models or dictionaries\n",
    "- **Ambiguous words**: Context is crucial for correct translation\n",
    "- **Formality levels**: Different languages express formality differently\n",
    "- **Word order differences**: Some language pairs require significant restructuring\n",
    "\n",
    "## Applications\n",
    "\n",
    "- **Document translation**: Legal, technical, and business documents\n",
    "- **Website localization**: Multilingual websites and applications\n",
    "- **Real-time communication**: Chat applications and video calls\n",
    "- **Content creation**: Multilingual marketing and educational materials\n",
    "- **Accessibility**: Making content available in multiple languages\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Learn about fine-tuning translation models for specific domains\n",
    "- Explore multilingual and zero-shot translation approaches\n",
    "- Study translation evaluation metrics and human evaluation\n",
    "- Practice with real-world translation datasets\n",
    "- Learn about computer-aided translation (CAT) tools\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [Hugging Face Translation Models](https://huggingface.co/models?pipeline_tag=translation)\n",
    "- [OPUS-MT Models](https://github.com/Helsinki-NLP/Opus-MT)\n",
    "- [M2M-100 Paper](https://arxiv.org/abs/2010.11125)\n",
    "- [BLEU Score](https://en.wikipedia.org/wiki/BLEU)\n",
    "- [WMT Translation Shared Tasks](http://www.statmt.org/wmt21/)\n",
    "- [Google Translate API](https://cloud.google.com/translate)\n",
    "- [Microsoft Translator](https://www.microsoft.com/en-us/translator/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}